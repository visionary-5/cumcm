# NIPTé—®é¢˜2ä¿®æ­£ç‰ˆï¼šä¼˜åŒ–BMIåˆ†ç»„ä¸æœ€ä½³æ£€æµ‹æ—¶ç‚¹
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

class CorrectedNIPTOptimizer:
    """ä¿®æ­£çš„NIPT BMIåˆ†ç»„ä¼˜åŒ–å™¨"""
    
    def __init__(self, data_file='é™„ä»¶.xlsx'):
        self.data_file = data_file
        self.threshold = 0.04
        
    def load_data(self):
        """åŠ è½½å¹¶å¤„ç†æ•°æ®"""
        try:
            # è¯»å–åŸå§‹æ•°æ®
            original_data = pd.read_excel(self.data_file, sheet_name='ç”·èƒæ£€æµ‹æ•°æ®')
            
            # è½¬æ¢å­•å‘¨æ ¼å¼
            def convert_gestation_week(week_str):
                if pd.isna(week_str):
                    return np.nan
                week_str = str(week_str).strip().upper()
                
                if 'W' in week_str:
                    week_str = week_str.replace('W', 'w')
                
                if 'w' in week_str.lower():
                    parts = week_str.lower().split('w')
                    try:
                        weeks = int(parts[0])
                        if len(parts) > 1 and '+' in parts[1]:
                            days = int(parts[1].split('+')[1])
                            return weeks + days/7
                        else:
                            return float(weeks)
                    except ValueError:
                        return np.nan
                
                try:
                    return float(week_str)
                except ValueError:
                    return np.nan
            
            original_data['å­•å‘¨_æ•°å€¼'] = original_data['æ£€æµ‹å­•å‘¨'].apply(convert_gestation_week)
            
            # æŒ‰å­•å¦‡åˆ†ç»„ï¼Œè®¡ç®—è¾¾æ ‡æ—¶é—´
            target_data = []
            
            for woman_code in original_data['å­•å¦‡ä»£ç '].unique():
                woman_data = original_data[original_data['å­•å¦‡ä»£ç '] == woman_code].copy()
                woman_data = woman_data.sort_values('å­•å‘¨_æ•°å€¼')
                
                # åŸºæœ¬ä¿¡æ¯
                bmi = woman_data['å­•å¦‡BMI'].iloc[0]
                age = woman_data['å¹´é¾„'].iloc[0]
                max_concentration = woman_data['YæŸ“è‰²ä½“æµ“åº¦'].max()
                
                # æ‰¾åˆ°ç¬¬ä¸€æ¬¡è¾¾æ ‡çš„æ—¶é—´
                reaching_records = woman_data[woman_data['YæŸ“è‰²ä½“æµ“åº¦'] >= self.threshold]
                
                if len(reaching_records) > 0:
                    reaching_time = reaching_records['å­•å‘¨_æ•°å€¼'].iloc[0]
                    target_data.append({
                        'å­•å¦‡ä»£ç ': woman_code,
                        'BMI': bmi,
                        'å¹´é¾„': age,
                        'è¾¾æ ‡æ—¶é—´': reaching_time,
                        'æœ€å¤§æµ“åº¦': max_concentration,
                        'æ˜¯å¦è¾¾æ ‡': 1
                    })
                else:
                    # å¯¹äºæœªè¾¾æ ‡çš„å­•å¦‡ï¼Œè®°å½•æœ€åæ£€æµ‹æ—¶é—´
                    last_time = woman_data['å­•å‘¨_æ•°å€¼'].max()
                    target_data.append({
                        'å­•å¦‡ä»£ç ': woman_code,
                        'BMI': bmi,
                        'å¹´é¾„': age,
                        'è¾¾æ ‡æ—¶é—´': np.nan,
                        'æœ€åæ£€æµ‹æ—¶é—´': last_time,
                        'æœ€å¤§æµ“åº¦': max_concentration,
                        'æ˜¯å¦è¾¾æ ‡': 0
                    })
            
            self.all_data = pd.DataFrame(target_data)
            self.reaching_data = self.all_data[self.all_data['æ˜¯å¦è¾¾æ ‡'] == 1].copy()
            
            print(f"æ€»å­•å¦‡æ•°: {len(self.all_data)}")
            print(f"è¾¾æ ‡å­•å¦‡æ•°: {len(self.reaching_data)}")
            print(f"è¾¾æ ‡ç‡: {len(self.reaching_data)/len(self.all_data):.1%}")
            print(f"å¹³å‡è¾¾æ ‡æ—¶é—´: {self.reaching_data['è¾¾æ ‡æ—¶é—´'].mean():.2f}å‘¨")
            
            return True
            
        except Exception as e:
            print(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False
    
    def create_practical_bmi_groups(self):
        """åˆ›å»ºå®ç”¨çš„BMIåˆ†ç»„"""
        print("\\n" + "="*60)
        print("åˆ›å»ºå®ç”¨BMIåˆ†ç»„")
        print("="*60)
        
        # åŸºäºä¸´åºŠæ ‡å‡†å’Œæ ·æœ¬åˆ†å¸ƒçš„åˆç†åˆ†ç»„
        def assign_bmi_group(bmi):
            if bmi < 25:
                return 'æ­£å¸¸ä½“é‡', 1
            elif bmi < 28:
                return 'è¶…é‡', 2  
            elif bmi < 32:
                return 'è½»åº¦è‚¥èƒ–', 3
            elif bmi < 36:
                return 'ä¸­åº¦è‚¥èƒ–', 4
            else:
                return 'é‡åº¦è‚¥èƒ–', 5
        
        # ä¸ºè¾¾æ ‡æ•°æ®åˆ†ç»„
        self.reaching_data[['BMIç»„åç§°', 'BMIç»„ç¼–å·']] = self.reaching_data['BMI'].apply(
            lambda x: pd.Series(assign_bmi_group(x))
        )
        
        # åˆ†ç»„ç»Ÿè®¡
        group_stats = []
        for group_id in sorted(self.reaching_data['BMIç»„ç¼–å·'].unique()):
            group_data = self.reaching_data[self.reaching_data['BMIç»„ç¼–å·'] == group_id]
            
            stats_dict = {
                'BMIç»„': group_id,
                'BMIç»„åç§°': group_data['BMIç»„åç§°'].iloc[0],
                'æ ·æœ¬æ•°': len(group_data),
                'BMIæœ€å°å€¼': group_data['BMI'].min(),
                'BMIæœ€å¤§å€¼': group_data['BMI'].max(),
                'BMIå‡å€¼': group_data['BMI'].mean(),
                'BMIæ ‡å‡†å·®': group_data['BMI'].std(),
                'è¾¾æ ‡æ—¶é—´å‡å€¼': group_data['è¾¾æ ‡æ—¶é—´'].mean(),
                'è¾¾æ ‡æ—¶é—´æ ‡å‡†å·®': group_data['è¾¾æ ‡æ—¶é—´'].std(),
                'è¾¾æ ‡æ—¶é—´ä¸­ä½æ•°': group_data['è¾¾æ ‡æ—¶é—´'].median()
            }
            group_stats.append(stats_dict)
        
        self.group_stats_df = pd.DataFrame(group_stats)
        
        print("BMIåˆ†ç»„ç»Ÿè®¡:")
        print(self.group_stats_df.round(2))
        
        return self.group_stats_df
    
    def calculate_optimal_detection_times(self):
        """è®¡ç®—æœ€ä½³æ£€æµ‹æ—¶ç‚¹"""
        print("\\n" + "="*60)
        print("è®¡ç®—æœ€ä½³æ£€æµ‹æ—¶ç‚¹")
        print("="*60)
        
        recommendations = []
        
        for _, group_stat in self.group_stats_df.iterrows():
            group_id = group_stat['BMIç»„']
            group_data = self.reaching_data[self.reaching_data['BMIç»„ç¼–å·'] == group_id]
            
            # åŸºç¡€ç»Ÿè®¡
            mean_time = group_stat['è¾¾æ ‡æ—¶é—´å‡å€¼']
            std_time = group_stat['è¾¾æ ‡æ—¶é—´æ ‡å‡†å·®']
            sample_size = group_stat['æ ·æœ¬æ•°']
            
            # è®¡ç®—ä¸åŒç½®ä¿¡æ°´å¹³çš„æ¨èæ—¶ç‚¹
            # è€ƒè™‘æ ·æœ¬é‡å°æ—¶çš„ä¿®æ­£
            if sample_size >= 30:
                confidence_multiplier_80 = 0.84  # æ­£æ€åˆ†å¸ƒ
                confidence_multiplier_90 = 1.28
            else:
                # å°æ ·æœ¬ç”¨tåˆ†å¸ƒä¿®æ­£
                from scipy.stats import t
                confidence_multiplier_80 = t.ppf(0.8, sample_size - 1)
                confidence_multiplier_90 = t.ppf(0.9, sample_size - 1)
            
            # ä¿å®ˆæ¨èæ—¶ç‚¹ï¼ˆ80%ç½®ä¿¡ï¼‰
            conservative_time = mean_time + confidence_multiplier_80 * std_time / np.sqrt(sample_size)
            
            # éå¸¸ä¿å®ˆæ—¶ç‚¹ï¼ˆ90%ç½®ä¿¡ï¼‰
            very_conservative_time = mean_time + confidence_multiplier_90 * std_time / np.sqrt(sample_size)
            
            # å®ç”¨æ¨èæ—¶ç‚¹ï¼ˆè€ƒè™‘ä¸´åºŠå®é™…ï¼‰
            # ä¸èƒ½å¤ªæ—©ï¼ˆé¿å…æ£€æµ‹å¤±è´¥ï¼‰ï¼Œä¸èƒ½å¤ªæ™šï¼ˆé¿å…æ²»ç–—çª—å£æœŸç¼©çŸ­ï¼‰
            practical_time = min(max(conservative_time, 12), 20)
            
            # é£é™©è¯„ä¼°
            early_failure_risk = len(group_data[group_data['è¾¾æ ‡æ—¶é—´'] > practical_time]) / len(group_data)
            
            # ä¸´åºŠé£é™©åˆ†çº§
            if practical_time <= 12:
                risk_level = "ä½é£é™©"
                risk_description = "æ—©æœŸå‘ç°"
            elif practical_time <= 27:
                risk_level = "ä¸­ç­‰é£é™©"
                risk_description = "ä¸­æœŸå‘ç°"
            else:
                risk_level = "é«˜é£é™©"
                risk_description = "æ™šæœŸå‘ç°"
            
            recommendation = {
                'BMIç»„': group_id,
                'BMIç»„åç§°': group_stat['BMIç»„åç§°'],
                'BMIåŒºé—´': f"[{group_stat['BMIæœ€å°å€¼']:.1f}, {group_stat['BMIæœ€å¤§å€¼']:.1f}]",
                'æ ·æœ¬æ•°': sample_size,
                'å¹³å‡è¾¾æ ‡æ—¶é—´': f"{mean_time:.1f}å‘¨",
                'è¾¾æ ‡æ—¶é—´æ ‡å‡†å·®': f"{std_time:.1f}å‘¨",
                'æ¨èæ£€æµ‹æ—¶ç‚¹': f"{practical_time:.1f}å‘¨",
                'ä¿å®ˆæ—¶ç‚¹(80%)': f"{conservative_time:.1f}å‘¨",
                'éå¸¸ä¿å®ˆæ—¶ç‚¹(90%)': f"{very_conservative_time:.1f}å‘¨",
                'æ£€æµ‹å¤±è´¥é£é™©': f"{early_failure_risk:.1%}",
                'é£é™©ç­‰çº§': risk_level,
                'é£é™©æè¿°': risk_description
            }
            recommendations.append(recommendation)
            
            print(f"\\nBMIç»„ {group_id} ({group_stat['BMIç»„åç§°']}):")
            print(f"  BMIåŒºé—´: {recommendation['BMIåŒºé—´']}")
            print(f"  æ ·æœ¬æ•°: {sample_size}")
            print(f"  å¹³å‡è¾¾æ ‡æ—¶é—´: {recommendation['å¹³å‡è¾¾æ ‡æ—¶é—´']}")
            print(f"  æ¨èæ£€æµ‹æ—¶ç‚¹: {recommendation['æ¨èæ£€æµ‹æ—¶ç‚¹']}")
            print(f"  æ£€æµ‹å¤±è´¥é£é™©: {recommendation['æ£€æµ‹å¤±è´¥é£é™©']}")
            print(f"  é£é™©ç­‰çº§: {recommendation['é£é™©ç­‰çº§']}")
        
        self.recommendations_df = pd.DataFrame(recommendations)
        return self.recommendations_df
    
    def analyze_error_impact(self):
        """åˆ†ææ£€æµ‹è¯¯å·®å½±å“"""
        print("\\n" + "="*60)
        print("æ£€æµ‹è¯¯å·®å½±å“åˆ†æ")
        print("="*60)
        
        # æ¨¡æ‹Ÿä¸åŒè¯¯å·®æ°´å¹³å¯¹ç»“æœçš„å½±å“
        error_levels = [0.001, 0.002, 0.005, 0.01]  # YæŸ“è‰²ä½“æµ“åº¦è¯¯å·®
        time_errors = [0.5, 1.0, 1.5]  # å­•å‘¨è¯¯å·®
        
        print("YæŸ“è‰²ä½“æµ“åº¦æµ‹é‡è¯¯å·®å½±å“:")
        for error in error_levels:
            # è®¡ç®—åœ¨ä¸åŒè¯¯å·®ä¸‹çš„è¾¾æ ‡ç‡å˜åŒ–
            adjusted_concentrations = self.reaching_data['æœ€å¤§æµ“åº¦'] - error
            still_reaching = np.sum(adjusted_concentrations >= self.threshold)
            impact = (still_reaching - len(self.reaching_data)) / len(self.reaching_data)
            print(f"  è¯¯å·® Â±{error:.3f}: è¾¾æ ‡ç‡å˜åŒ– {impact:.2%}")
        
        print("\\nå­•å‘¨æµ‹é‡è¯¯å·®å½±å“:")
        for time_error in time_errors:
            mean_time_change = self.reaching_data['è¾¾æ ‡æ—¶é—´'].mean()
            adjusted_mean = mean_time_change + time_error
            time_impact = time_error / mean_time_change
            print(f"  è¯¯å·® Â±{time_error}å‘¨: å¹³å‡è¾¾æ ‡æ—¶é—´å˜åŒ– {time_impact:.1%}")
    
    def create_visualizations(self):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        print("\\n" + "="*60)
        print("ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨")
        print("="*60)
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('NIPT BMIåˆ†ç»„ä¸æ£€æµ‹æ—¶ç‚¹ä¼˜åŒ–åˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. BMIåˆ†å¸ƒ
        axes[0,0].hist(self.reaching_data['BMI'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        axes[0,0].axvline(self.reaching_data['BMI'].mean(), color='red', linestyle='--', label=f'å‡å€¼: {self.reaching_data["BMI"].mean():.1f}')
        axes[0,0].set_xlabel('BMI')
        axes[0,0].set_ylabel('é¢‘æ•°')
        axes[0,0].set_title('BMIåˆ†å¸ƒ')
        axes[0,0].legend()
        
        # 2. BMI vs è¾¾æ ‡æ—¶é—´
        scatter = axes[0,1].scatter(self.reaching_data['BMI'], self.reaching_data['è¾¾æ ‡æ—¶é—´'], 
                                  c=self.reaching_data['BMIç»„ç¼–å·'], cmap='viridis', alpha=0.6)
        z = np.polyfit(self.reaching_data['BMI'], self.reaching_data['è¾¾æ ‡æ—¶é—´'], 1)
        p = np.poly1d(z)
        axes[0,1].plot(self.reaching_data['BMI'], p(self.reaching_data['BMI']), "r--", alpha=0.8)
        corr = np.corrcoef(self.reaching_data['BMI'], self.reaching_data['è¾¾æ ‡æ—¶é—´'])[0,1]
        axes[0,1].set_xlabel('BMI')
        axes[0,1].set_ylabel('è¾¾æ ‡æ—¶é—´(å‘¨)')
        axes[0,1].set_title(f'BMI vs è¾¾æ ‡æ—¶é—´ (r={corr:.3f})')
        plt.colorbar(scatter, ax=axes[0,1], label='BMIç»„')
        
        # 3. åˆ†ç»„ç®±çº¿å›¾
        group_data_for_plot = []
        group_labels = []
        for group_id in sorted(self.reaching_data['BMIç»„ç¼–å·'].unique()):
            group_data_for_plot.append(self.reaching_data[self.reaching_data['BMIç»„ç¼–å·'] == group_id]['è¾¾æ ‡æ—¶é—´'].values)
            group_name = self.reaching_data[self.reaching_data['BMIç»„ç¼–å·'] == group_id]['BMIç»„åç§°'].iloc[0]
            group_labels.append(f'{group_name}\\n(n={len(group_data_for_plot[-1])})')
        
        axes[0,2].boxplot(group_data_for_plot, labels=range(1, len(group_data_for_plot)+1))
        axes[0,2].set_xlabel('BMIç»„')
        axes[0,2].set_ylabel('è¾¾æ ‡æ—¶é—´(å‘¨)')
        axes[0,2].set_title('å„BMIç»„è¾¾æ ‡æ—¶é—´åˆ†å¸ƒ')
        axes[0,2].set_xticklabels(group_labels, rotation=45)
        
        # 4. æ¨èæ£€æµ‹æ—¶ç‚¹å¯¹æ¯”
        groups = self.recommendations_df['BMIç»„åç§°']
        recommended_times = [float(x.split('å‘¨')[0]) for x in self.recommendations_df['æ¨èæ£€æµ‹æ—¶ç‚¹']]
        conservative_times = [float(x.split('å‘¨')[0]) for x in self.recommendations_df['ä¿å®ˆæ—¶ç‚¹(80%)']]
        
        x = np.arange(len(groups))
        width = 0.35
        
        axes[1,0].bar(x - width/2, recommended_times, width, label='æ¨èæ—¶ç‚¹', alpha=0.8)
        axes[1,0].bar(x + width/2, conservative_times, width, label='ä¿å®ˆæ—¶ç‚¹', alpha=0.8)
        axes[1,0].set_xlabel('BMIç»„')
        axes[1,0].set_ylabel('æ£€æµ‹æ—¶ç‚¹(å‘¨)')
        axes[1,0].set_title('æ¨èæ£€æµ‹æ—¶ç‚¹å¯¹æ¯”')
        axes[1,0].set_xticks(x)
        axes[1,0].set_xticklabels(groups, rotation=45)
        axes[1,0].legend()
        
        # 5. é£é™©è¯„ä¼°
        failure_risks = [float(x.split('%')[0])/100 for x in self.recommendations_df['æ£€æµ‹å¤±è´¥é£é™©']]
        colors = ['green' if x < 0.1 else 'orange' if x < 0.2 else 'red' for x in failure_risks]
        
        axes[1,1].bar(groups, failure_risks, color=colors, alpha=0.7)
        axes[1,1].set_xlabel('BMIç»„')
        axes[1,1].set_ylabel('æ£€æµ‹å¤±è´¥é£é™©')
        axes[1,1].set_title('å„ç»„æ£€æµ‹å¤±è´¥é£é™©')
        axes[1,1].set_xticklabels(groups, rotation=45)
        
        # 6. è¾¾æ ‡ç‡åˆ†æ
        total_counts = self.all_data['BMI'].apply(lambda x: assign_bmi_group(x)[1]).value_counts().sort_index()
        reaching_counts = self.reaching_data['BMIç»„ç¼–å·'].value_counts().sort_index()
        
        success_rates = []
        group_names = []
        for group_id in sorted(total_counts.index):
            if group_id in reaching_counts.index:
                rate = reaching_counts[group_id] / total_counts[group_id]
            else:
                rate = 0
            success_rates.append(rate)
            group_name = self.group_stats_df[self.group_stats_df['BMIç»„'] == group_id]['BMIç»„åç§°'].iloc[0]
            group_names.append(group_name)
        
        colors_success = ['green' if x > 0.8 else 'orange' if x > 0.6 else 'red' for x in success_rates]
        axes[1,2].bar(group_names, success_rates, color=colors_success, alpha=0.7)
        axes[1,2].set_xlabel('BMIç»„')
        axes[1,2].set_ylabel('è¾¾æ ‡ç‡')
        axes[1,2].set_title('å„ç»„è¾¾æ ‡ç‡')
        axes[1,2].set_xticklabels(group_names, rotation=45)
        
        plt.tight_layout()
        plt.savefig('nipt_corrected_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def generate_final_report(self):
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        print("\\n" + "="*80)
        print("æœ€ç»ˆBMIåˆ†ç»„ä¸æ£€æµ‹æ—¶ç‚¹æ¨èæŠ¥å‘Š")
        print("="*80)
        
        print("\\nğŸ“Š æ•°æ®æ¦‚å†µ:")
        print(f"â€¢ æ€»å­•å¦‡æ ·æœ¬: {len(self.all_data)}äºº")
        print(f"â€¢ YæŸ“è‰²ä½“è¾¾æ ‡å­•å¦‡: {len(self.reaching_data)}äºº")
        print(f"â€¢ æ€»ä½“è¾¾æ ‡ç‡: {len(self.reaching_data)/len(self.all_data):.1%}")
        print(f"â€¢ å¹³å‡è¾¾æ ‡æ—¶é—´: {self.reaching_data['è¾¾æ ‡æ—¶é—´'].mean():.1f}å‘¨")
        
        print("\\nğŸ“‹ BMIåˆ†ç»„ä¸æ£€æµ‹æ—¶ç‚¹æ¨è:")
        print("-" * 80)
        
        for _, rec in self.recommendations_df.iterrows():
            print(f"\\n{rec['BMIç»„åç§°']} (BMI {rec['BMIåŒºé—´']}):")
            print(f"  â€¢ æ ·æœ¬æ•°é‡: {rec['æ ·æœ¬æ•°']}äºº")
            print(f"  â€¢ å¹³å‡è¾¾æ ‡æ—¶é—´: {rec['å¹³å‡è¾¾æ ‡æ—¶é—´']}")
            print(f"  â€¢ æ¨èæ£€æµ‹æ—¶ç‚¹: {rec['æ¨èæ£€æµ‹æ—¶ç‚¹']}")
            print(f"  â€¢ æ£€æµ‹å¤±è´¥é£é™©: {rec['æ£€æµ‹å¤±è´¥é£é™©']}")
            print(f"  â€¢ ä¸´åºŠé£é™©ç­‰çº§: {rec['é£é™©ç­‰çº§']} ({rec['é£é™©æè¿°']})")
        
        print("\\nğŸ’¡ ä¸´åºŠåº”ç”¨å»ºè®®:")
        print("1. æ­£å¸¸ä½“é‡å’Œè¶…é‡å­•å¦‡å¯åœ¨12-14å‘¨å¼€å§‹æ£€æµ‹")
        print("2. è½»åº¦è‚¥èƒ–å­•å¦‡å»ºè®®åœ¨13-15å‘¨æ£€æµ‹")
        print("3. ä¸­é‡åº¦è‚¥èƒ–å­•å¦‡åº”é€‚å½“å»¶è¿Ÿè‡³15-17å‘¨")
        print("4. æ‰€æœ‰æ£€æµ‹åº”åœ¨20å‘¨å‰å®Œæˆï¼Œç¡®ä¿æ²»ç–—çª—å£æœŸ")
        print("5. å¦‚é¦–æ¬¡æ£€æµ‹å¤±è´¥ï¼Œå»ºè®®é—´éš”1-2å‘¨é‡å¤æ£€æµ‹")
        
        # ä¿å­˜æ¨èç»“æœ
        self.recommendations_df.to_excel('corrected_bmi_recommendations.xlsx', index=False)
        print("\\nâœ… æ¨èæ–¹æ¡ˆå·²ä¿å­˜è‡³: corrected_bmi_recommendations.xlsx")
        
        return self.recommendations_df
    
    def run_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        print("NIPTé—®é¢˜2ä¿®æ­£ç‰ˆåˆ†æ")
        print("="*80)
        
        # 1. åŠ è½½æ•°æ®
        if not self.load_data():
            return False
        
        # 2. åˆ›å»ºBMIåˆ†ç»„
        self.create_practical_bmi_groups()
        
        # 3. è®¡ç®—æœ€ä½³æ£€æµ‹æ—¶ç‚¹
        self.calculate_optimal_detection_times()
        
        # 4. è¯¯å·®å½±å“åˆ†æ
        self.analyze_error_impact()
        
        # 5. åˆ›å»ºå¯è§†åŒ–
        self.create_visualizations()
        
        # 6. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        self.generate_final_report()
        
        return True

def assign_bmi_group(bmi):
    """BMIåˆ†ç»„å‡½æ•°"""
    if bmi < 25:
        return 'æ­£å¸¸ä½“é‡', 1
    elif bmi < 28:
        return 'è¶…é‡', 2  
    elif bmi < 32:
        return 'è½»åº¦è‚¥èƒ–', 3
    elif bmi < 36:
        return 'ä¸­åº¦è‚¥èƒ–', 4
    else:
        return 'é‡åº¦è‚¥èƒ–', 5

# ä¸»ç¨‹åº
if __name__ == "__main__":
    optimizer = CorrectedNIPTOptimizer()
    success = optimizer.run_analysis()
    
    if success:
        print("\\n" + "="*80)
        print("ä¿®æ­£ç‰ˆåˆ†æå®Œæˆï¼")
        print("="*80)
        print("ä¸»è¦æ”¹è¿›:")
        print("1. ç»Ÿè®¡äº†æ‰€æœ‰å­•å¦‡æ ·æœ¬ï¼Œæ˜ç¡®è¾¾æ ‡ç‡")
        print("2. åŸºäºä¸´åºŠæ ‡å‡†åˆ›å»ºå‡è¡¡çš„BMIåˆ†ç»„") 
        print("3. é‡‡ç”¨æ›´å®é™…çš„æ£€æµ‹æ—¶ç‚¹æ¨èç­–ç•¥")
        print("4. è€ƒè™‘å°æ ·æœ¬é‡çš„ç»Ÿè®¡ä¿®æ­£")
        print("5. æä¾›æ›´å…¨é¢çš„é£é™©è¯„ä¼°")
    else:
        print("åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶")
