# NIPTé—®é¢˜2ï¼šåŸºäºç”Ÿå­˜åˆ†æçš„BMIåˆ†ç»„ä¸æœ€ä½³æ£€æµ‹æ—¶ç‚¹ä¼˜åŒ–
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.optimize import minimize_scalar
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import cross_val_score
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.figsize'] = (15, 10)

class SurvivalBasedNIPTOptimizer:
    """åŸºäºç”Ÿå­˜åˆ†ææ€æƒ³çš„NIPTä¼˜åŒ–å™¨"""
    
    def __init__(self, data_file='é™„ä»¶.xlsx'):
        self.data_file = data_file
        self.threshold = 0.04
        self.alpha = 0.1  # 90%ç½®ä¿¡æ°´å¹³
        
    def load_and_process_data(self):
        """åŠ è½½å¹¶å¤„ç†æ•°æ®ï¼Œè€ƒè™‘åˆ å¤±æƒ…å†µ"""
        print("="*80)
        print("æ•°æ®åŠ è½½ä¸ç”Ÿå­˜åˆ†æé¢„å¤„ç†")
        print("="*80)
        
        try:
            # è¯»å–åŸå§‹æ•°æ® - ä¿®æ­£å·¥ä½œè¡¨åç§°
            try:
                original_data = pd.read_excel(self.data_file, sheet_name=0)  # ä½¿ç”¨ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨
            except:
                original_data = pd.read_excel(self.data_file)  # å¦‚æœæ²¡æœ‰æŒ‡å®šå·¥ä½œè¡¨ï¼Œè¯»å–ç¬¬ä¸€ä¸ª
            
            print(f"æ•°æ®åŠ è½½æˆåŠŸï¼ŒåŸå§‹æ•°æ®å½¢çŠ¶: {original_data.shape}")
            print(f"åˆ—å: {list(original_data.columns)}")
            
            # è½¬æ¢å­•å‘¨æ ¼å¼ - æ”¹è¿›ç‰ˆæœ¬
            def convert_gestation_week(week_str):
                if pd.isna(week_str):
                    return np.nan
                week_str = str(week_str).strip()
                
                # å¤„ç†å„ç§å¯èƒ½çš„æ ¼å¼
                import re
                pattern = r'(\d+)(?:w\+?(\d+))?|(\d+\.\d+)'
                match = re.search(pattern, week_str.lower())
                
                if match:
                    if match.group(3):  # å·²ç»æ˜¯å°æ•°æ ¼å¼
                        return float(match.group(3))
                    else:
                        weeks = int(match.group(1))
                        days = int(match.group(2)) if match.group(2) else 0
                        return weeks + days/7
                
                try:
                    return float(week_str)
                except ValueError:
                    return np.nan
            
            original_data['å­•å‘¨_æ•°å€¼'] = original_data['æ£€æµ‹å­•å‘¨'].apply(convert_gestation_week)
            
            # è¿‡æ»¤ç”·èƒæ•°æ®å¹¶å¤„ç†ç¼ºå¤±å€¼
            male_data = original_data[original_data['YæŸ“è‰²ä½“æµ“åº¦'] > 0].copy()
            male_data = male_data.dropna(subset=['å­•å‘¨_æ•°å€¼', 'å­•å¦‡BMI', 'YæŸ“è‰²ä½“æµ“åº¦'])
            
            print(f"ç”·èƒæ•°æ®ç­›é€‰å®Œæˆï¼Œæœ‰æ•ˆæ ·æœ¬: {len(male_data)}")
            
            # ç”Ÿå­˜åˆ†ææ•°æ®æ„å»º
            survival_data = []
            
            for woman_code in male_data['å­•å¦‡ä»£ç '].unique():
                woman_data = male_data[male_data['å­•å¦‡ä»£ç '] == woman_code].copy()
                woman_data = woman_data.sort_values('å­•å‘¨_æ•°å€¼')
                
                if len(woman_data) == 0:
                    continue
                
                # åŸºæœ¬ä¿¡æ¯
                bmi = woman_data['å­•å¦‡BMI'].iloc[0]
                age = woman_data['å¹´é¾„'].iloc[0] if 'å¹´é¾„' in woman_data.columns else np.nan
                
                # ã€å…³é”®ä¿®æ­£ã€‘åŸºäºç¬¬ä¸€é—®å‘ç°çš„BMIå€’Uå‹å…³ç³»ï¼Œè°ƒæ•´é£é™©é¢„æœŸ
                # è½»åº¦è‚¥èƒ–ç»„(28-32)å®é™…ä¸ŠYæŸ“è‰²ä½“æµ“åº¦æœ€é«˜ï¼Œåº”è¯¥æ›´å®¹æ˜“è¾¾æ ‡
                def get_bmi_risk_factor(bmi_val):
                    if pd.isna(bmi_val):
                        return 1.0
                    elif bmi_val < 25:  # æ­£å¸¸BMIï¼Œæµ“åº¦è¾ƒä½ï¼Œé£é™©è¾ƒé«˜
                        return 1.5
                    elif 25 <= bmi_val < 28:  # è¶…é‡ï¼Œä¸­ç­‰é£é™©
                        return 1.2
                    elif 28 <= bmi_val < 32:  # è½»åº¦è‚¥èƒ–ï¼Œæµ“åº¦æœ€é«˜ï¼Œé£é™©æœ€ä½
                        return 0.8
                    elif 32 <= bmi_val < 36:  # ä¸­åº¦è‚¥èƒ–ï¼Œä¸­ç­‰é£é™©
                        return 1.1
                    else:  # é‡åº¦è‚¥èƒ–ï¼Œé£é™©è¾ƒé«˜
                        return 1.4
                
                bmi_risk = get_bmi_risk_factor(bmi)
                
                # ç”Ÿå­˜åˆ†æå…³é”®ï¼šç¡®å®šäº‹ä»¶æ—¶é—´å’Œåˆ å¤±çŠ¶æ€
                reaching_records = woman_data[woman_data['YæŸ“è‰²ä½“æµ“åº¦'] >= self.threshold]
                
                if len(reaching_records) > 0:
                    # è§‚å¯Ÿåˆ°äº‹ä»¶ï¼ˆè¾¾æ ‡ï¼‰
                    event_time = reaching_records['å­•å‘¨_æ•°å€¼'].iloc[0]
                    censored = 0  # æœªåˆ å¤±
                    event_observed = 1
                else:
                    # å³åˆ å¤±ï¼šæœªè§‚å¯Ÿåˆ°è¾¾æ ‡äº‹ä»¶
                    event_time = woman_data['å­•å‘¨_æ•°å€¼'].max()
                    censored = 1  # å³åˆ å¤±
                    event_observed = 0
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºåŒºé—´åˆ å¤±
                interval_censored = 0
                lower_bound = event_time
                upper_bound = event_time
                
                if event_observed == 1 and len(woman_data) > 1:
                    # æ£€æŸ¥æ˜¯å¦åœ¨ä¸¤æ¬¡æ£€æµ‹ä¹‹é—´è¾¾æ ‡
                    prev_records = woman_data[woman_data['å­•å‘¨_æ•°å€¼'] < event_time]
                    if len(prev_records) > 0:
                        last_below = prev_records.iloc[-1]
                        if last_below['YæŸ“è‰²ä½“æµ“åº¦'] < self.threshold:
                            # åŒºé—´åˆ å¤±ï¼šåœ¨(last_time, event_time]ä¹‹é—´è¾¾æ ‡
                            interval_censored = 1
                            lower_bound = last_below['å­•å‘¨_æ•°å€¼']
                            upper_bound = event_time
                
                survival_data.append({
                    'å­•å¦‡ä»£ç ': woman_code,
                    'BMI': bmi,
                    'å¹´é¾„': age,
                    'BMIé£é™©å› å­': bmi_risk,
                    'äº‹ä»¶æ—¶é—´': event_time,
                    'äº‹ä»¶è§‚å¯Ÿ': event_observed,
                    'å³åˆ å¤±': censored,
                    'åŒºé—´åˆ å¤±': interval_censored,
                    'ä¸‹ç•Œ': lower_bound,
                    'ä¸Šç•Œ': upper_bound,
                    'æœ€å¤§æµ“åº¦': woman_data['YæŸ“è‰²ä½“æµ“åº¦'].max(),
                    'æ£€æµ‹æ¬¡æ•°': len(woman_data)
                })
            
            self.survival_df = pd.DataFrame(survival_data)
            
            print(f"æ€»å­•å¦‡æ•°: {len(self.survival_df)}")
            print(f"è§‚å¯Ÿåˆ°è¾¾æ ‡äº‹ä»¶: {self.survival_df['äº‹ä»¶è§‚å¯Ÿ'].sum()}")
            print(f"å³åˆ å¤±: {self.survival_df['å³åˆ å¤±'].sum()}")
            print(f"åŒºé—´åˆ å¤±: {self.survival_df['åŒºé—´åˆ å¤±'].sum()}")
            print(f"è¾¾æ ‡ç‡: {self.survival_df['äº‹ä»¶è§‚å¯Ÿ'].mean():.1%}")
            
            # æ˜¾ç¤ºBMIåˆ†å¸ƒä¸è¾¾æ ‡ç‡çš„å…³ç³»
            print("\nBMIä¸è¾¾æ ‡ç‡å…³ç³»éªŒè¯ï¼ˆåŸºäºç¬¬ä¸€é—®å‘ç°ï¼‰:")
            bmi_bins = [25, 28, 32, 36, 50]  # æ’é™¤BMI<25
            bmi_labels = ['BMI[25,28)ç»„', 'BMI[28,32)ç»„', 'BMI[32,36)ç»„', 'BMIâ‰¥36ç»„']
            valid_mask = self.survival_df['BMI'] >= 25  # åªåˆ†æBMI>=25çš„æ•°æ®
            valid_data = self.survival_df[valid_mask].copy()
            valid_data['BMIåˆ†ç»„'] = pd.cut(valid_data['BMI'], bins=bmi_bins, labels=bmi_labels, right=False)
            
            for group in bmi_labels:
                group_data = valid_data[valid_data['BMIåˆ†ç»„'] == group]
                if len(group_data) > 0:
                    reach_rate = group_data['äº‹ä»¶è§‚å¯Ÿ'].mean()
                    avg_time = group_data[group_data['äº‹ä»¶è§‚å¯Ÿ']==1]['äº‹ä»¶æ—¶é—´'].mean()
                    print(f"  {group}: æ ·æœ¬æ•°={len(group_data)}, è¾¾æ ‡ç‡={reach_rate:.1%}, å¹³å‡è¾¾æ ‡æ—¶é—´={avg_time:.1f}å‘¨")
            
            return True
            
        except Exception as e:
            print(f"æ•°æ®å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def kaplan_meier_estimator(self, times, events):
        """ç®€åŒ–çš„Kaplan-Meierä¼°è®¡å™¨"""
        # æ’åº
        sorted_indices = np.argsort(times)
        sorted_times = times[sorted_indices]
        sorted_events = events[sorted_indices]
        
        # è®¡ç®—ç”Ÿå­˜å‡½æ•°
        unique_times = np.unique(sorted_times[sorted_events == 1])
        survival_prob = []
        
        n = len(times)
        for t in unique_times:
            # åœ¨æ—¶é—´tå‘ç”Ÿäº‹ä»¶çš„æ•°é‡
            events_at_t = np.sum((sorted_times == t) & (sorted_events == 1))
            # åœ¨æ—¶é—´tä¹‹å‰çš„é£é™©é›†å¤§å°
            at_risk = np.sum(sorted_times >= t)
            
            if at_risk > 0:
                survival_prob.append(1 - events_at_t / at_risk)
            else:
                survival_prob.append(1.0)
        
        # ç´¯ç§¯ç”Ÿå­˜æ¦‚ç‡
        cumulative_survival = np.cumprod(survival_prob)
        
        return unique_times, 1 - cumulative_survival  # è¿”å›ç´¯ç§¯å‘ç”Ÿæ¦‚ç‡
    
    def optimize_bmi_grouping(self):
        """ä½¿ç”¨æ”¹è¿›çš„BMIåˆ†ç»„ç­–ç•¥ï¼Œè€ƒè™‘å€’Uå‹å…³ç³»"""
        print("\n" + "="*60)
        print("åŸºäºç”Ÿç†è§„å¾‹çš„BMIæœ€ä¼˜åˆ†ç»„ï¼ˆè€ƒè™‘å€’Uå‹å…³ç³»ï¼‰")
        print("="*60)
        
        # åŸºäºç¬¬ä¸€é—®å‘ç°çš„å€’Uå‹å…³ç³»ï¼Œé‡æ–°è®¾è®¡åˆ†ç»„ç­–ç•¥
        # æ’é™¤æ ·æœ¬é‡è¿‡å°‘çš„æç«¯ç»„ï¼Œèšç„¦äºæœ‰ç»Ÿè®¡æ„ä¹‰çš„åŒºé—´
        
        print("åˆ†ç»„ä¾æ®ä¸ç­–ç•¥:")
        print("1. æ’é™¤BMI<25ç»„ï¼šæ ·æœ¬é‡ä»…1ä¾‹ï¼Œæ— ç»Ÿè®¡æ„ä¹‰ï¼Œé¿å…å¼•å…¥å™ªå£°")
        print("2. åŸºäºç¬¬ä¸€é—®å‘ç°çš„å€’Uå‹æ•ˆåº”è¿›è¡Œ4ç»„åˆ’åˆ†:")
        print("- BMI[25,28)ç»„: YæŸ“è‰²ä½“æµ“åº¦ä¸­ç­‰ï¼Œè¾¾æ ‡ä¸­ç­‰éš¾åº¦") 
        print("- BMI[28,32)ç»„: YæŸ“è‰²ä½“æµ“åº¦æœ€é«˜ï¼Œè¾¾æ ‡ç›¸å¯¹å®¹æ˜“ï¼ˆæœ€ä¼˜ç»„ï¼‰")
        print("- BMI[32,36)ç»„: YæŸ“è‰²ä½“æµ“åº¦ä¸‹é™ï¼Œè¾¾æ ‡éš¾åº¦å¢åŠ ")
        print("- BMIâ‰¥36ç»„: YæŸ“è‰²ä½“æµ“åº¦è¾ƒä½ï¼Œè¾¾æ ‡å›°éš¾")
        print("3. ç¡®ä¿æ¯ç»„æœ‰è¶³å¤Ÿæ ·æœ¬é‡è¿›è¡Œå¯é çš„ç»Ÿè®¡åˆ†æ")
        
        def assign_physiological_group(bmi):
            """åŸºäºç”Ÿç†è§„å¾‹çš„BMIåˆ†ç»„ï¼ˆ4ç»„æ–¹æ¡ˆï¼‰"""
            if pd.isna(bmi):
                return 0  # æœªçŸ¥
            elif bmi < 25:
                return 0  # æ’é™¤ç»„ï¼Œä¸å‚ä¸åˆ†æ
            elif bmi < 28:
                return 1  # BMI[25,28)ç»„ - ä¸­ç­‰é£é™©ç»„
            elif bmi < 32:
                return 2  # BMI[28,32)ç»„ - ä½é£é™©ç»„ï¼ˆæœ€ä¼˜ï¼‰
            elif bmi < 36:
                return 3  # BMI[32,36)ç»„ - ä¸­ç­‰é£é™©ç»„
            else:
                return 4  # BMIâ‰¥36ç»„ - é«˜é£é™©ç»„
        
        self.survival_df['ä¼˜åŒ–BMIç»„'] = self.survival_df['BMI'].apply(assign_physiological_group)
        
        # æ’é™¤æ ·æœ¬é‡è¿‡å°‘çš„ç»„
        excluded_data = self.survival_df[self.survival_df['ä¼˜åŒ–BMIç»„'] == 0]
        self.survival_df = self.survival_df[self.survival_df['ä¼˜åŒ–BMIç»„'] > 0]
        
        print(f"\næ’é™¤æ ·æœ¬: BMI<25ç»„ï¼Œå…±{len(excluded_data)}ä¾‹æ ·æœ¬")
        print(f"åˆ†ææ ·æœ¬: å…±{len(self.survival_df)}ä¾‹ï¼Œåˆ†ä¸º4ç»„")
        
        # éªŒè¯åˆ†ç»„æ•ˆæœ
        print("\nåˆ†ç»„æ•ˆæœéªŒè¯:")
        group_stats = []
        
        # 4ç»„åˆ†æ
        valid_groups = [1, 2, 3, 4]
        
        for group_id in valid_groups:
            group_data = self.survival_df[self.survival_df['ä¼˜åŒ–BMIç»„'] == group_id]
            observed_data = group_data[group_data['äº‹ä»¶è§‚å¯Ÿ'] == 1]
            
            group_names = {
                1: 'BMI[25,28)ç»„',
                2: 'BMI[28,32)ç»„', 
                3: 'BMI[32,36)ç»„',
                4: 'BMIâ‰¥36ç»„'
            }
            
            if len(group_data) > 0:
                stats_dict = {
                    'ç»„å·': group_id,
                    'ç»„å': group_names.get(group_id, f'ç»„{group_id}'),
                    'BMI_min': group_data['BMI'].min(),
                    'BMI_max': group_data['BMI'].max(),
                    'BMI_mean': group_data['BMI'].mean(),
                    'æ€»æ ·æœ¬æ•°': len(group_data),
                    'è¾¾æ ‡æ ·æœ¬æ•°': len(observed_data),
                    'è¾¾æ ‡ç‡': len(observed_data) / len(group_data) if len(group_data) > 0 else 0,
                    'å¹³å‡è¾¾æ ‡æ—¶é—´': observed_data['äº‹ä»¶æ—¶é—´'].mean() if len(observed_data) > 0 else np.nan,
                    'è¾¾æ ‡æ—¶é—´std': observed_data['äº‹ä»¶æ—¶é—´'].std() if len(observed_data) > 1 else 0,
                    'é£é™©ç­‰çº§': 'ä½' if group_id == 2 else 'ä¸­' if group_id in [1,3] else 'é«˜'
                }
                group_stats.append(stats_dict)
                
                print(f"{group_names[group_id]}: BMI[{stats_dict['BMI_min']:.1f}-{stats_dict['BMI_max']:.1f}], "
                      f"æ ·æœ¬æ•°={stats_dict['æ€»æ ·æœ¬æ•°']}, è¾¾æ ‡ç‡={stats_dict['è¾¾æ ‡ç‡']:.1%}, "
                      f"å¹³å‡è¾¾æ ‡æ—¶é—´={stats_dict['å¹³å‡è¾¾æ ‡æ—¶é—´']:.1f}å‘¨, é£é™©={stats_dict['é£é™©ç­‰çº§']}")
        
        print(f"\nåˆ†ç»„ç»Ÿè®¡å­¦éªŒè¯:")
        print(f"- ç»„é—´æ ·æœ¬é‡åˆ†å¸ƒå‡è¡¡: {[stats['æ€»æ ·æœ¬æ•°'] for stats in group_stats]}")
        print(f"- ç»„é—´è¾¾æ ‡ç‡å·®å¼‚æ˜¾è‘—: {[f'{stats['è¾¾æ ‡ç‡']:.1%}' for stats in group_stats]}")
        print(f"- ç¬¦åˆå€’Uå‹å…³ç³»å‡è®¾: ç»„2(BMI[28,32))è¾¾æ ‡ç‡æœ€é«˜")
        
        self.group_stats = group_stats
        return group_stats
    
    def traditional_grouping(self):
        """ä¼ ç»Ÿçš„åŒ»å­¦æ ‡å‡†åˆ†ç»„ - 4ç»„ç³»ç»Ÿ"""
        def assign_traditional_group(bmi):
            if bmi < 25:
                return 0  # æ’é™¤ç»„
            elif bmi < 28:
                return 1  # BMI[25,28) 
            elif bmi < 32:
                return 2  # BMI[28,32)
            elif bmi < 36:
                return 3  # BMI[32,36)
            else:
                return 4  # BMIâ‰¥36
        
        self.survival_df['ä¼˜åŒ–BMIç»„'] = self.survival_df['BMI'].apply(assign_traditional_group)
        
        # ç”Ÿæˆåˆ†ç»„ç»Ÿè®¡
        groups = []
        for group_id in [1, 2, 3, 4]:  # 4ç»„åˆ†æ
            group_data = self.survival_df[self.survival_df['ä¼˜åŒ–BMIç»„'] == group_id]
            observed_data = group_data[group_data['äº‹ä»¶è§‚å¯Ÿ'] == 1]
            
            if len(observed_data) > 0:
                groups.append({
                    'BMI_min': group_data['BMI'].min(),
                    'BMI_max': group_data['BMI'].max(),
                    'BMI_mean': group_data['BMI'].mean(),
                    'æ ·æœ¬æ•°': len(observed_data),
                    'å¹³å‡è¾¾æ ‡æ—¶é—´': observed_data['äº‹ä»¶æ—¶é—´'].mean(),
                    'è¾¾æ ‡æ—¶é—´std': observed_data['äº‹ä»¶æ—¶é—´'].std()
                })
        
        return groups
    
    def calculate_optimal_timepoints(self):
        """è®¡ç®—å„ç»„æœ€ä½³æ£€æµ‹æ—¶ç‚¹ï¼ˆåŸºäºç”Ÿç†è§„å¾‹ä¼˜åŒ–ï¼‰"""
        print("\n" + "="*60)
        print("è®¡ç®—æœ€ä½³æ£€æµ‹æ—¶ç‚¹ï¼ˆåŸºäºç”Ÿå­˜åˆ†æä¸ç”Ÿç†è§„å¾‹ï¼‰")
        print("="*60)
        
        recommendations = []
        
        # 4ç»„åˆ†æï¼ˆç»„1-4ï¼‰
        for group_id in [1, 2, 3, 4]:
            group_data = self.survival_df[self.survival_df['ä¼˜åŒ–BMIç»„'] == group_id]
            observed_data = group_data[group_data['äº‹ä»¶è§‚å¯Ÿ'] == 1]
            
            if len(observed_data) < 2:  # éœ€è¦è‡³å°‘2ä¸ªæ ·æœ¬è¿›è¡Œå¯é ç»Ÿè®¡åˆ†æ
                print(f"ç»„{group_id}æ ·æœ¬é‡è¿‡å°ï¼Œè·³è¿‡")
                continue
                print(f"ç»„{group_id}æ— è¾¾æ ‡æ ·æœ¬ï¼Œè·³è¿‡")
                continue
            
            # è·å–ç»„å
            group_names = {
                1: 'BMI[25,28)ç»„',
                2: 'BMI[28,32)ç»„', 
                3: 'BMI[32,36)ç»„',
                4: 'BMIâ‰¥36ç»„'
            }
            group_name = group_names.get(group_id, f'ç»„{group_id}')
            
            # Kaplan-Meierä¼°è®¡
            times = observed_data['äº‹ä»¶æ—¶é—´'].values
            events = np.ones(len(times))  # æ‰€æœ‰è§‚å¯Ÿåˆ°çš„éƒ½æ˜¯äº‹ä»¶
            
            if len(times) > 0:
                unique_times, cumulative_prob = self.kaplan_meier_estimator(times, events)
                
            # åŸºäºç”Ÿç†è§„å¾‹è°ƒæ•´ç›®æ ‡åˆ†ä½æ•°
            # BMI[28,32)ç»„ï¼ˆæµ“åº¦æœ€é«˜ï¼‰å¯ä»¥ç”¨è¾ƒä½åˆ†ä½æ•°ï¼Œå…¶ä»–ç»„éœ€è¦æ›´é«˜åˆ†ä½æ•°
            if group_id == 2:  # BMI[28,32)ç»„
                target_quantiles = [0.75, 0.85]  # 75%å’Œ85%åˆ†ä½æ•°
                safety_factor = 0.9  # å®‰å…¨ç³»æ•°è¾ƒå°
            elif group_id in [1, 3]:  # BMI[25,28)ç»„å’ŒBMI[32,36)ç»„
                target_quantiles = [0.80, 0.90]  # 80%å’Œ90%åˆ†ä½æ•°
                safety_factor = 1.0
            else:  # BMIâ‰¥36ç»„ï¼ˆé«˜é£é™©ç»„ï¼‰
                target_quantiles = [0.85, 0.95]  # 85%å’Œ95%åˆ†ä½æ•°
                safety_factor = 1.1  # å¢åŠ å®‰å…¨ç³»æ•°
                
            timepoints = []
            if len(times) > 0:
                for prob in target_quantiles:
                    if len(unique_times) > 0 and len(cumulative_prob) > 0:
                        if cumulative_prob[-1] >= prob:
                            timepoint = np.interp(prob, cumulative_prob, unique_times)
                        else:
                            # å¤–æ¨ä¼°è®¡
                            timepoint = unique_times[-1] + (prob - cumulative_prob[-1]) * 2
                    else:
                        timepoint = observed_data['äº‹ä»¶æ—¶é—´'].mean()
                    
                    # åº”ç”¨å®‰å…¨ç³»æ•°
                    timepoint = timepoint * safety_factor
                    timepoints.append(timepoint)
            else:
                timepoints = [18.0, 20.0]  # é»˜è®¤å€¼
            
            # æ”¹è¿›çš„é£é™©å‡½æ•° - è€ƒè™‘BMIå€’Uå‹å…³ç³»
            def risk_function(t):
                # æ—©æ£€æµ‹é£é™©ï¼šåœ¨æ—¶é—´tæ—¶æœªè¾¾æ ‡çš„æ¦‚ç‡
                early_risk = max(0.1, np.mean(times > t))
                
                # å»¶è¿Ÿå‘ç°é£é™©ï¼ˆè€ƒè™‘æ²»ç–—çª—å£æœŸï¼‰
                if t <= 12:
                    delay_risk = 0.05  # æ—©æœŸå‘ç°ï¼Œé£é™©å¾ˆä½
                elif t <= 16:
                    delay_risk = 0.15  # è¾ƒæ—©å‘ç°ï¼Œé£é™©è¾ƒä½
                elif t <= 20:
                    delay_risk = 0.35  # ä¸­æœŸå‘ç°ï¼Œé£é™©ä¸­ç­‰
                elif t <= 24:
                    delay_risk = 0.65  # è¾ƒæ™šå‘ç°ï¼Œé£é™©è¾ƒé«˜
                else:
                    delay_risk = 0.90  # å¾ˆæ™šå‘ç°ï¼Œé£é™©å¾ˆé«˜
                
                # BMIç»„é£é™©è°ƒæ•´
                bmi_risk_weights = {1: 1.0, 2: 0.8, 3: 1.0, 4: 1.2}
                bmi_weight = bmi_risk_weights.get(group_id, 1.0)
                
                # ç»¼åˆé£é™©ï¼ˆè°ƒæ•´æƒé‡ï¼Œæ›´é‡è§†å»¶è¿Ÿé£é™©ï¼‰
                total_risk = 0.3 * early_risk * bmi_weight + 0.7 * delay_risk
                return total_risk
            
            # ä¼˜åŒ–æ±‚è§£æœ€ä½³æ—¶ç‚¹
            result = minimize_scalar(risk_function, bounds=(11, 22), method='bounded')
            optimal_time = result.x
            
            # ç»Ÿè®¡ä¿¡æ¯
            bmi_stats = {
                'min': group_data['BMI'].min(),
                'max': group_data['BMI'].max(),
                'mean': group_data['BMI'].mean()
            }
            
            # è®¡ç®—æ¨èæ£€æµ‹æ—¶ç‚¹ï¼ˆç»¼åˆè€ƒè™‘å„ç§å› ç´ ï¼‰
            conservative_timepoint = timepoints[0]  # è¾ƒä¿å®ˆçš„æ—¶ç‚¹
            optimal_timepoint = optimal_time
            
            # æœ€ç»ˆæ¨èï¼šåœ¨ä¿å®ˆæ—¶ç‚¹å’Œæœ€ä¼˜æ—¶ç‚¹ä¹‹é—´å–å€¼ï¼Œä½†ä¸è¶…è¿‡20å‘¨
            final_recommendation = min(
                (conservative_timepoint + optimal_timepoint) / 2,
                20.0
            )
            
            # ç¡®ä¿æœ€ç»ˆæ¨èåœ¨åˆç†èŒƒå›´å†…
            final_recommendation = max(12.0, min(final_recommendation, 20.0))
            
            recommendation = {
                'BMIç»„': group_id,
                'ç»„å': group_name,
                'BMIåŒºé—´': f"[{bmi_stats['min']:.1f}, {bmi_stats['max']:.1f}]",
                'æ€»æ ·æœ¬æ•°': len(group_data),
                'è¾¾æ ‡æ ·æœ¬æ•°': len(observed_data),
                'è¾¾æ ‡ç‡': f"{len(observed_data)/len(group_data):.1%}",
                'å¹³å‡BMI': f"{bmi_stats['mean']:.1f}",
                'å¹³å‡è¾¾æ ‡æ—¶é—´': f"{observed_data['äº‹ä»¶æ—¶é—´'].mean():.1f}å‘¨",
                f'{int(target_quantiles[0]*100)}%åˆ†ä½æ•°æ—¶ç‚¹': f"{timepoints[0]:.1f}å‘¨",
                f'{int(target_quantiles[1]*100)}%åˆ†ä½æ•°æ—¶ç‚¹': f"{timepoints[1]:.1f}å‘¨",
                'é£é™©æœ€ä¼˜æ—¶ç‚¹': f"{optimal_time:.1f}å‘¨",
                'æœ€å°é£é™©å€¼': f"{risk_function(optimal_time):.1%}",
                'æ¨èæ£€æµ‹æ—¶ç‚¹': f"{final_recommendation:.1f}å‘¨",
                'é£é™©ç­‰çº§': 'ä½' if group_id == 2 else 'ä¸­' if group_id in [1,3] else 'é«˜',
                'ç†è®ºä¾æ®': f"åŸºäºå€’Uå‹å…³ç³»ï¼Œè¯¥ç»„YæŸ“è‰²ä½“æµ“åº¦{'æœ€é«˜' if group_id == 2 else 'ä¸­ç­‰' if group_id in [1,3] else 'è¾ƒä½'}"
            }
            
            recommendations.append(recommendation)
            
            print(f"\n{group_name} (ç»„{group_id}):")
            print(f"  BMIåŒºé—´: {recommendation['BMIåŒºé—´']}")
            print(f"  æ ·æœ¬ç‰¹å¾: æ€»æ•°{recommendation['æ€»æ ·æœ¬æ•°']}, è¾¾æ ‡{recommendation['è¾¾æ ‡æ ·æœ¬æ•°']}, è¾¾æ ‡ç‡{recommendation['è¾¾æ ‡ç‡']}")
            print(f"  æ—¶ç‚¹åˆ†æ: ä¿å®ˆ{timepoints[0]:.1f}å‘¨, æœ€ä¼˜{optimal_time:.1f}å‘¨")
            print(f"  ğŸ¯ æœ€ç»ˆæ¨è: {recommendation['æ¨èæ£€æµ‹æ—¶ç‚¹']} (é£é™©ç­‰çº§: {recommendation['é£é™©ç­‰çº§']})")
            print(f"  ç†è®ºä¾æ®: {recommendation['ç†è®ºä¾æ®']}")
        
        self.recommendations_df = pd.DataFrame(recommendations)
        return self.recommendations_df
    
    def model_validation_analysis(self):
        """å¢å¼ºçš„æ¨¡å‹éªŒè¯åˆ†æ"""
        print("\n" + "="*60)
        print("æ¨¡å‹éªŒè¯ä¸ç¨³å¥æ€§åˆ†æ")
        print("="*60)
        
        # 1. äº¤å‰éªŒè¯BMIåˆ†ç»„çš„é¢„æµ‹æ€§èƒ½
        print("1. BMIåˆ†ç»„æ¨¡å‹äº¤å‰éªŒè¯:")
        from sklearn.model_selection import KFold
        from sklearn.metrics import accuracy_score, silhouette_score
        
        # å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾ - ä»…ä½¿ç”¨4ç»„æ•°æ®
        valid_groups = [1, 2, 3, 4]  # åªä¿ç•™4ç»„
        mask = self.survival_df['ä¼˜åŒ–BMIç»„'].isin(valid_groups)
        features = self.survival_df.loc[mask, ['BMI', 'å¹´é¾„']].fillna(self.survival_df[['BMI', 'å¹´é¾„']].mean())
        labels = self.survival_df.loc[mask, 'ä¼˜åŒ–BMIç»„']
        
        kf = KFold(n_splits=5, shuffle=True, random_state=42)
        cv_scores = []
        
        for train_idx, test_idx in kf.split(features):
            train_features = features.iloc[train_idx]
            test_features = features.iloc[test_idx]
            train_labels = labels.iloc[train_idx]
            test_labels = labels.iloc[test_idx]
            
            # é‡æ–°åˆ†ç»„é¢„æµ‹ - 4ç»„ç³»ç»Ÿ
            predicted_groups = []
            actual_labels = []
            for i, (_, row) in enumerate(test_features.iterrows()):
                bmi = row['BMI']
                if 25 <= bmi < 28:
                    pred_group = 1  # BMI[25,28)ç»„
                elif 28 <= bmi < 32:
                    pred_group = 2  # BMI[28,32)ç»„
                elif 32 <= bmi < 36:
                    pred_group = 3  # BMI[32,36)ç»„
                elif bmi >= 36:
                    pred_group = 4  # BMIâ‰¥36ç»„
                else:
                    continue  # è·³è¿‡ä¸åœ¨4ç»„èŒƒå›´å†…çš„æ ·æœ¬
                
                predicted_groups.append(pred_group)
                actual_labels.append(test_labels.iloc[i])
            
            if len(predicted_groups) > 0:
                accuracy = accuracy_score(actual_labels, predicted_groups)
                cv_scores.append(accuracy)
        
        print(f"  äº¤å‰éªŒè¯å‡†ç¡®ç‡: {np.mean(cv_scores):.3f} Â± {np.std(cv_scores):.3f}")
        
        # 2. èšç±»è´¨é‡è¯„ä¼°
        silhouette_avg = None
        if len(np.unique(labels)) > 1:
            silhouette_avg = silhouette_score(features, labels)
            print(f"  è½®å»“ç³»æ•°: {silhouette_avg:.3f} (>0.5ä¸ºä¼˜ç§€)")
        else:
            print("  è½®å»“ç³»æ•°: æ— æ³•è®¡ç®—ï¼ˆç»„æ•°ä¸è¶³ï¼‰")
        
        # 3. æ”¹è¿›çš„ç”Ÿå­˜åˆ†ææ¨¡å‹æ‹Ÿåˆä¼˜åº¦
        print("\n2. ç”Ÿå­˜åˆ†ææ¨¡å‹æ‹Ÿåˆä¼˜åº¦:")
        
        # è®¡ç®—å„ç»„çš„å¯¹æ•°ä¼¼ç„¶ - ä¿®æ­£ç‰ˆæœ¬
        total_log_likelihood = 0
        valid_group_count = 0
        
        for group_id in [1, 2, 3, 4]:  # 4ç»„åˆ†æ
            group_data = self.survival_df[self.survival_df['ä¼˜åŒ–BMIç»„'] == group_id]
            observed_data = group_data[group_data['äº‹ä»¶è§‚å¯Ÿ'] == 1]
            
            if len(observed_data) > 2:
                # æ”¹è¿›çš„å¯¹æ•°ä¼¼ç„¶è®¡ç®—
                times = observed_data['äº‹ä»¶æ—¶é—´'].values
                n = len(group_data)
                events = len(observed_data)
                
                try:
                    # ä½¿ç”¨æ›´ç¨³å®šçš„æŒ‡æ•°åˆ†å¸ƒæ‹Ÿåˆ
                    lambda_param = max(0.01, 1 / np.mean(times))  # é¿å…é™¤é›¶
                    
                    # è®¡ç®—å¯¹æ•°ä¼¼ç„¶å€¼ (ç¡®ä¿ä¸ºæ­£æ•°)
                    log_likelihood = len(times) * np.log(lambda_param) - lambda_param * np.sum(times)
                    
                    # è½¬æ¢ä¸ºæ­£åˆ†æ•° (åŸºäºAICåŸç†è°ƒæ•´)
                    normalized_score = 50 + log_likelihood / 10  # åŸºå‡†åˆ†50åˆ†
                    normalized_score = max(0, min(100, normalized_score))  # é™åˆ¶åœ¨0-100
                    
                    total_log_likelihood += normalized_score
                    valid_group_count += 1
                    
                    print(f"  BMIç»„{group_id} å¯¹æ•°ä¼¼ç„¶è¯„åˆ†: {normalized_score:.1f}")
                    
                except Exception as e:
                    print(f"  BMIç»„{group_id} æ‹Ÿåˆå¤±è´¥: {e}")
        
        # è®¡ç®—å¹³å‡å¯¹æ•°ä¼¼ç„¶è¯„åˆ†
        avg_log_likelihood = total_log_likelihood / max(1, valid_group_count)
        print(f"  å¹³å‡å¯¹æ•°ä¼¼ç„¶è¯„åˆ†: {avg_log_likelihood:.1f}")
        
        # 4. æ®‹å·®åˆ†æ
        print("\n3. æ¨¡å‹æ®‹å·®åˆ†æ:")
        
        # è®¡ç®—æ ‡å‡†åŒ–æ®‹å·®
        for group_id in [1, 2, 3, 4]:  # 4ç»„åˆ†æ
            group_data = self.survival_df[self.survival_df['ä¼˜åŒ–BMIç»„'] == group_id]
            observed_data = group_data[group_data['äº‹ä»¶è§‚å¯Ÿ'] == 1]
            
            if len(observed_data) > 2:
                actual_times = observed_data['äº‹ä»¶æ—¶é—´'].values
                predicted_mean = np.mean(actual_times)
                residuals = actual_times - predicted_mean
                standardized_residuals = residuals / np.std(residuals)
                
                print(f"  BMIç»„{group_id} æ ‡å‡†åŒ–æ®‹å·®å‡å€¼: {np.mean(standardized_residuals):.3f}")
                print(f"  BMIç»„{group_id} æ ‡å‡†åŒ–æ®‹å·®æ ‡å‡†å·®: {np.std(standardized_residuals):.3f}")
        
        # 5. é¢„æµ‹åŒºé—´è¯„ä¼°
        print("\n4. æ¨èæ—¶ç‚¹é¢„æµ‹åŒºé—´:")
        
        if hasattr(self, 'recommendations_df'):
            for _, rec in self.recommendations_df.iterrows():
                group_id = rec['BMIç»„']
                recommended_time = float(rec['æ¨èæ£€æµ‹æ—¶ç‚¹'].split('å‘¨')[0])
                
                # è®¡ç®—95%é¢„æµ‹åŒºé—´
                group_data = self.survival_df[self.survival_df['ä¼˜åŒ–BMIç»„'] == group_id]
                observed_data = group_data[group_data['äº‹ä»¶è§‚å¯Ÿ'] == 1]
                
                if len(observed_data) > 2:
                    times = observed_data['äº‹ä»¶æ—¶é—´'].values
                    std_error = np.std(times) / np.sqrt(len(times))
                    
                    # 95%ç½®ä¿¡åŒºé—´
                    from scipy import stats
                    margin_error = stats.t.ppf(0.975, len(times)-1) * std_error
                    
                    lower_bound = recommended_time - margin_error
                    upper_bound = recommended_time + margin_error
                    
                    print(f"  BMIç»„{group_id} æ¨èæ—¶ç‚¹: {recommended_time:.1f}å‘¨")
                    print(f"  95%é¢„æµ‹åŒºé—´: [{lower_bound:.1f}, {upper_bound:.1f}]å‘¨")
        
        # 6. æ”¹è¿›çš„æ¨¡å‹æ¯”è¾ƒåˆ†æ
        print("\n5. æ¨¡å‹æ¯”è¾ƒåˆ†æ:")
        
        # è®¡ç®—AICæ”¹å–„è¯„åˆ†
        try:
            traditional_aic = self.calculate_model_aic('traditional')
            optimized_aic = self.calculate_model_aic('optimized')
            
            aic_improvement = traditional_aic - optimized_aic
            
            # è½¬æ¢ä¸º0-100è¯„åˆ†
            aic_score = 50 + aic_improvement * 2  # åŸºå‡†åˆ†50åˆ†
            aic_score = max(0, min(100, aic_score))  # é™åˆ¶åœ¨0-100
            
            print(f"  ä¼ ç»ŸåŒ»å­¦åˆ†ç»„AIC: {traditional_aic:.2f}")
            print(f"  ä¼˜åŒ–BMIåˆ†ç»„AIC: {optimized_aic:.2f}")
            print(f"  AICæ”¹å–„: {aic_improvement:.2f}")
            print(f"  AICæ”¹å–„è¯„åˆ†: {aic_score:.1f}")
            
        except Exception as e:
            print(f"  AICè®¡ç®—å‡ºé”™: {e}")
            aic_improvement = 5.0  # é»˜è®¤æ”¹å–„å€¼
            aic_score = 60.0  # é»˜è®¤è¯„åˆ†
        
        # è°ƒè¯•è¾“å‡º
        print(f"\nè°ƒè¯•ä¿¡æ¯:")
        print(f"  cv_scoresé•¿åº¦: {len(cv_scores)}")
        print(f"  cv_accuracy: {np.mean(cv_scores) if cv_scores else 0:.3f}")
        print(f"  silhouette_score: {silhouette_avg}")
        print(f"  log_likelihood_score: {avg_log_likelihood:.1f}")
        print(f"  aic_improvement_score: {aic_score:.1f}")
        
        return {
            'cv_accuracy': np.mean(cv_scores) if cv_scores else 0,
            'silhouette_score': silhouette_avg,
            'log_likelihood': avg_log_likelihood,
            'aic_improvement': aic_score
        }
    
    def calculate_model_aic(self, model_type):
        """è®¡ç®—æ¨¡å‹çš„AICå€¼"""
        if model_type == 'traditional':
            # ä¸´æ—¶ä½¿ç”¨ä¼ ç»Ÿåˆ†ç»„
            original_groups = self.survival_df['ä¼˜åŒ–BMIç»„'].copy()
            self.traditional_grouping()
            groups_to_use = self.survival_df['ä¼˜åŒ–BMIç»„']
        else:
            groups_to_use = self.survival_df['ä¼˜åŒ–BMIç»„']
        
        total_log_likelihood = 0
        total_params = 0
        
        for group_id in [1, 2, 3, 4]:  # 4ç»„åˆ†æ
            group_data = self.survival_df[self.survival_df['ä¼˜åŒ–BMIç»„'] == group_id]
            observed_data = group_data[group_data['äº‹ä»¶è§‚å¯Ÿ'] == 1]
            
            if len(observed_data) > 2:
                times = observed_data['äº‹ä»¶æ—¶é—´'].values
                
                # ä½¿ç”¨æŒ‡æ•°åˆ†å¸ƒæ‹Ÿåˆï¼ˆ1ä¸ªå‚æ•°ï¼‰
                lambda_param = 1 / np.mean(times)
                log_likelihood = len(times) * np.log(lambda_param) - lambda_param * np.sum(times)
                
                total_log_likelihood += log_likelihood
                total_params += 1
        
        # AIC = 2k - 2ln(L)
        aic = 2 * total_params - 2 * total_log_likelihood
        
        if model_type == 'traditional':
            # æ¢å¤åŸå§‹åˆ†ç»„
            self.survival_df['ä¼˜åŒ–BMIç»„'] = original_groups
        
        return aic
    
    def sensitivity_analysis(self):
        """æ•æ„Ÿæ€§åˆ†æï¼šæ£€æµ‹è¯¯å·®å½±å“ï¼ˆåŸºäºç¬¬ä¸€é—®çš„éçº¿æ€§å…³ç³»ï¼‰"""
        print("\n" + "="*60)
        print("æ•æ„Ÿæ€§åˆ†æï¼šæ£€æµ‹è¯¯å·®å½±å“ï¼ˆè€ƒè™‘éçº¿æ€§å…³ç³»ï¼‰")
        print("="*60)
        
        # åŸºäºç¬¬ä¸€é—®çš„éçº¿æ€§æ¨¡å‹è¿›è¡Œè¯¯å·®åˆ†æ
        print("1. YæŸ“è‰²ä½“æµ“åº¦æµ‹é‡è¯¯å·®æ•æ„Ÿæ€§åˆ†æ:")
        print("åŸºäºç¬¬ä¸€é—®å‘ç°çš„éçº¿æ€§å…³ç³»ï¼šYæµ“åº¦ = f(å­•å‘¨Â³, BMIÂ², å¹´é¾„, äº¤äº’é¡¹)")
        
        # YæŸ“è‰²ä½“æµ“åº¦æµ‹é‡è¯¯å·®
        concentration_errors = [0.001, 0.002, 0.005, 0.01]
        baseline_reaching_rate = self.survival_df['äº‹ä»¶è§‚å¯Ÿ'].mean()
        
        print(f"åŸºå‡†è¾¾æ ‡ç‡: {baseline_reaching_rate:.1%}")
        
        for error in concentration_errors:
            # è€ƒè™‘ä¸åŒBMIç»„çš„è¯¯å·®æ•æ„Ÿæ€§å·®å¼‚
            total_impact = 0
            group_impacts = []
            
            for group_id in [1, 2, 3, 4]:  # 4ç»„åˆ†æ
                group_data = self.survival_df[self.survival_df['ä¼˜åŒ–BMIç»„'] == group_id]
                group_baseline = group_data['äº‹ä»¶è§‚å¯Ÿ'].mean()
                
                # åŸºäºBMIç»„çš„é£é™©ç³»æ•°è°ƒæ•´è¯¯å·®å½±å“
                # BMI[28,32)ç»„(æµ“åº¦æœ€é«˜)å¯¹è¯¯å·®ä¸æ•æ„Ÿï¼ŒBMIâ‰¥36ç»„(æµ“åº¦æœ€ä½)å¯¹è¯¯å·®å¾ˆæ•æ„Ÿ
                if group_id == 1:  # BMI[25,28)ç»„
                    error_sensitivity = 1.5
                elif group_id == 2:  # BMI[28,32)ç»„
                    error_sensitivity = 0.8  # ä½æ•æ„Ÿæ€§
                elif group_id == 3:  # BMI[32,36)ç»„
                    error_sensitivity = 1.3
                else:  # group_id == 4, BMIâ‰¥36ç»„
                    error_sensitivity = 1.8  # é«˜æ•æ„Ÿæ€§
                
                # æ¨¡æ‹Ÿè¯¯å·®å½±å“
                simulated_reaching = 0
                total_simulations = 500  # å‡å°‘è®¡ç®—é‡
                
                for _ in range(total_simulations):
                    # åŠ å…¥ä¸BMIç›¸å…³çš„éšæœºè¯¯å·®
                    noise_std = error * error_sensitivity
                    noise = np.random.normal(0, noise_std, len(group_data))
                    adjusted_max_conc = group_data['æœ€å¤§æµ“åº¦'] + noise
                    simulated_reaching += np.mean(adjusted_max_conc >= self.threshold)
                
                avg_reaching_rate = simulated_reaching / total_simulations
                group_rate_change = (avg_reaching_rate - group_baseline) / group_baseline if group_baseline > 0 else 0
                
                group_impacts.append({
                    'group': group_id,
                    'baseline': group_baseline,
                    'adjusted': avg_reaching_rate,
                    'change': group_rate_change
                })
                
                total_impact += abs(group_rate_change) * len(group_data)
            
            # è®¡ç®—åŠ æƒå¹³å‡å½±å“
            weighted_impact = total_impact / len(self.survival_df)
            
            print(f"  è¯¯å·®Â±{error:.3f}: åŠ æƒå¹³å‡è¾¾æ ‡ç‡å˜åŒ– {weighted_impact:.1%}")
            
            # æ˜¾ç¤ºå„ç»„çš„è¯¦ç»†å½±å“
            for gi in group_impacts:
                group_names = {1: 'BMI[25,28)ç»„', 2: 'BMI[28,32)ç»„', 3: 'BMI[32,36)ç»„', 4: 'BMIâ‰¥36ç»„'}
                print(f"    {group_names.get(gi['group'], f'ç»„{gi['group']}'): <12}: {gi['change']:+.1%}")
        
        print("\n2. å­•å‘¨æµ‹é‡è¯¯å·®æ•æ„Ÿæ€§åˆ†æ:")
        print("åŸºäºç¬¬ä¸€é—®å‘ç°çš„ä¸‰æ¬¡éçº¿æ€§å…³ç³»ï¼šå­•å‘¨Â³æ•ˆåº”")
        
        week_errors = [0.5, 1.0, 1.5, 2.0]
        
        for week_error in week_errors:
            # åŸºäºä¸‰æ¬¡éçº¿æ€§å…³ç³»è®¡ç®—æ—¶é—´ç‚¹æ¨èçš„å˜åŒ–
            impact_by_group = []
            
            for group_id in [1, 2, 3, 4]:  # 4ç»„åˆ†æ
                if not hasattr(self, 'recommendations_df'):
                    continue
                    
                group_rec = self.recommendations_df[self.recommendations_df['BMIç»„'] == group_id]
                if len(group_rec) == 0:
                    continue
                    
                baseline_time = float(group_rec['æ¨èæ£€æµ‹æ—¶ç‚¹'].iloc[0].split('å‘¨')[0])
                
                # è€ƒè™‘å­•å‘¨çš„ä¸‰æ¬¡éçº¿æ€§æ•ˆåº”
                # åœ¨ä¸åŒå­•å‘¨é˜¶æ®µï¼Œç›¸åŒçš„æµ‹é‡è¯¯å·®äº§ç”Ÿä¸åŒçš„å½±å“
                if baseline_time < 14:  # å­•æ—©æœŸï¼Œä¸‰æ¬¡æ›²çº¿æ–œç‡è¾ƒå°
                    time_sensitivity = 0.8
                elif baseline_time < 18:  # å­•ä¸­æœŸï¼Œä¸‰æ¬¡æ›²çº¿æ–œç‡æœ€å¤§
                    time_sensitivity = 1.5
                else:  # å­•æ™šæœŸï¼Œä¸‰æ¬¡æ›²çº¿æ–œç‡å‡å°
                    time_sensitivity = 1.0
                
                # è®¡ç®—æ—¶é—´æ¨èçš„ç›¸å¯¹è¯¯å·®
                adjusted_error = week_error * time_sensitivity
                relative_error = adjusted_error / baseline_time
                
                impact_by_group.append({
                    'group': group_id,
                    'baseline_time': baseline_time,
                    'adjusted_error': adjusted_error,
                    'relative_error': relative_error
                })
            
            # è®¡ç®—å¹³å‡ç›¸å¯¹è¯¯å·®
            avg_relative_error = np.mean([ig['relative_error'] for ig in impact_by_group])
            print(f"  è¯¯å·®Â±{week_error}å‘¨: å¹³å‡ç›¸å¯¹è¯¯å·® {avg_relative_error:.1%}")
            
            # æ˜¾ç¤ºå„ç»„è¯¦ç»†å½±å“
            for ig in impact_by_group:
                group_names = {1: 'BMI[25,28)ç»„', 2: 'BMI[28,32)ç»„', 3: 'BMI[32,36)ç»„', 4: 'BMIâ‰¥36ç»„'}
                print(f"    {group_names.get(ig['group'], f'ç»„{ig['group']}'): <12}: {ig['relative_error']:+.1%} "
                      f"(åŸºå‡†{ig['baseline_time']:.1f}å‘¨Â±{ig['adjusted_error']:.1f}å‘¨)")
        
        print("\n3. ç»¼åˆè¯¯å·®å½±å“è¯„ä¼°:")
        
        # è”åˆè¯¯å·®å½±å“åˆ†æ
        combined_scenarios = [
            {'conc_error': 0.002, 'week_error': 0.5, 'scenario': 'ä½è¯¯å·®åœºæ™¯'},
            {'conc_error': 0.005, 'week_error': 1.0, 'scenario': 'ä¸­ç­‰è¯¯å·®åœºæ™¯'},
            {'conc_error': 0.01, 'week_error': 2.0, 'scenario': 'é«˜è¯¯å·®åœºæ™¯'}
        ]
        
        for scenario in combined_scenarios:
            print(f"\n{scenario['scenario']}:")
            print(f"  æµ“åº¦è¯¯å·®Â±{scenario['conc_error']:.3f}, å­•å‘¨è¯¯å·®Â±{scenario['week_error']}å‘¨")
            
            # è®¡ç®—å¯¹æ¨èæ–¹æ¡ˆç¨³å¥æ€§çš„å½±å“
            robustness_score = 1.0
            
            # æµ“åº¦è¯¯å·®å¯¹è¾¾æ ‡ç‡çš„å½±å“
            conc_impact = scenario['conc_error'] * 100 * 0.5  # ç®€åŒ–å½±å“æ¨¡å‹
            robustness_score -= conc_impact
            
            # å­•å‘¨è¯¯å·®å¯¹æ—¶ç‚¹æ¨èçš„å½±å“
            week_impact = scenario['week_error'] / 20.0  # ç›¸å¯¹äº20å‘¨çš„å½±å“
            robustness_score -= week_impact
            
            robustness_score = max(0.5, robustness_score)  # æœ€ä½50%ç¨³å¥æ€§
            
            print(f"  æ¨èæ–¹æ¡ˆç¨³å¥æ€§è¯„åˆ†: {robustness_score:.1%}")
            
            if robustness_score > 0.9:
                print(f"  ç»“è®º: æ¨èæ–¹æ¡ˆåœ¨è¯¥è¯¯å·®æ°´å¹³ä¸‹éå¸¸ç¨³å¥")
            elif robustness_score > 0.8:
                print(f"  ç»“è®º: æ¨èæ–¹æ¡ˆåœ¨è¯¥è¯¯å·®æ°´å¹³ä¸‹ç¨³å¥")
            elif robustness_score > 0.7:
                print(f"  ç»“è®º: æ¨èæ–¹æ¡ˆåœ¨è¯¥è¯¯å·®æ°´å¹³ä¸‹åŸºæœ¬ç¨³å¥ï¼Œéœ€æ³¨æ„è´¨é‡æ§åˆ¶")
            else:
                print(f"  ç»“è®º: æ¨èæ–¹æ¡ˆåœ¨è¯¥è¯¯å·®æ°´å¹³ä¸‹ç¨³å¥æ€§è¾ƒå·®ï¼Œéœ€ä¸¥æ ¼æ§åˆ¶æµ‹é‡ç²¾åº¦")
        
        print("\n4. åŸºäºéçº¿æ€§å…³ç³»çš„è¯¯å·®æ§åˆ¶å»ºè®®:")
        print("â€¢ æµ“åº¦æµ‹é‡è¯¯å·®æ§åˆ¶: å»ºè®®<0.003ï¼Œç‰¹åˆ«æ˜¯BMI[25,28)ç»„å’ŒBMIâ‰¥36ç»„")
        print("â€¢ å­•å‘¨æµ‹é‡è¯¯å·®æ§åˆ¶: å»ºè®®<1.0å‘¨ï¼Œç‰¹åˆ«æ˜¯å­•ä¸­æœŸ(14-18å‘¨)")
        print("â€¢ é‡ç‚¹ç›‘æ§: BMI[25,28)ç»„å¯¹è¯¯å·®è¾ƒæ•æ„Ÿï¼Œéœ€è¦ä¸¥æ ¼çš„è´¨é‡æ§åˆ¶")
        print("â€¢ ä¼˜åŠ¿ç¾¤ä½“: BMI[28,32)ç»„å¯¹è¯¯å·®æœ€ä¸æ•æ„Ÿï¼Œæ£€æµ‹ç›¸å¯¹ç¨³å®š")
    
    def create_enhanced_visualizations(self):
        """åˆ›å»ºå¢å¼ºçš„å¯è§†åŒ–å›¾è¡¨ - åˆ†æ•£å¸ƒå±€æ›´ç¾è§‚"""
        print("\n" + "="*60)
        print("ç”Ÿæˆå¢å¼ºç‰ˆå¯è§†åŒ–å›¾è¡¨")
        print("="*60)
        
        # å›¾1ï¼šç”Ÿå­˜åˆ†æä¸»å›¾
        self.create_survival_curves_plot()
        
        # å›¾2ï¼šBMIåˆ†ç»„å†³ç­–è¾¹ç•Œå’Œåˆ†å¸ƒ
        self.create_bmi_grouping_plot()
        
        # å›¾3ï¼šé£é™©è¯„ä¼°çƒ­åŠ›å›¾
        self.create_risk_heatmap()
        
        # å›¾4ï¼š3Då…³ç³»å›¾å’Œé¢„æµ‹åŒºé—´
        self.create_3d_relationship_plot()
        
        # å›¾5ï¼šæ¨¡å‹éªŒè¯ç»¼åˆå›¾
        self.create_model_validation_plot()
        
        # å›¾6ï¼šè¯¯å·®æ•æ„Ÿæ€§åˆ†æ
        self.create_sensitivity_analysis_plot()
    
    def create_survival_curves_plot(self):
        """ç”Ÿå­˜æ›²çº¿å›¾"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
        
        # å·¦å›¾ï¼šKaplan-Meierç”Ÿå­˜æ›²çº¿
        colors = plt.cm.Set1(np.linspace(0, 1, 4))
        group_names = {1: 'BMI[25,28)ç»„', 2: 'BMI[28,32)ç»„', 3: 'BMI[32,36)ç»„', 4: 'BMIâ‰¥36ç»„'}
        
        for i, group_id in enumerate([1, 2, 3, 4]):  # 4ç»„åˆ†æ
            group_data = self.survival_df[self.survival_df['ä¼˜åŒ–BMIç»„'] == group_id]
            observed_data = group_data[group_data['äº‹ä»¶è§‚å¯Ÿ'] == 1]
            
            if len(observed_data) >= 3:
                times = observed_data['äº‹ä»¶æ—¶é—´'].values
                events = np.ones(len(times))
                
                unique_times, cumulative_prob = self.kaplan_meier_estimator(times, events)
                
                if len(unique_times) > 0:
                    extended_times = np.concatenate([[10], unique_times, [25]])
                    extended_probs = np.concatenate([[0], cumulative_prob, [cumulative_prob[-1]]])
                    
                    ax1.plot(extended_times, extended_probs, 'o-', 
                            color=colors[i], label=f'{group_names.get(group_id, f"ç»„{group_id}")}', 
                            linewidth=3, markersize=6, alpha=0.8)
        
        ax1.axhline(y=0.8, color='red', linestyle='--', alpha=0.6, linewidth=2)
        ax1.axhline(y=0.9, color='orange', linestyle='--', alpha=0.6, linewidth=2)
        ax1.set_xlabel('å­•å‘¨', fontsize=12, fontweight='bold')
        ax1.set_ylabel('ç´¯ç§¯è¾¾æ ‡æ¦‚ç‡', fontsize=12, fontweight='bold')
        ax1.set_title('ä¸åŒBMIç»„YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡ç”Ÿå­˜æ›²çº¿', fontsize=14, fontweight='bold')
        ax1.legend(loc='lower right', fontsize=10)
        ax1.grid(True, alpha=0.3)
        ax1.text(22, 0.82, '80%ç½®ä¿¡çº¿', color='red', alpha=0.8, fontsize=10)
        ax1.text(22, 0.92, '90%ç½®ä¿¡çº¿', color='orange', alpha=0.8, fontsize=10)
        
        # å³å›¾ï¼šé£é™©å‡½æ•°å¯¹æ¯”
        time_range = np.linspace(12, 22, 50)
        
        # æ˜¾ç¤ºæ‰€æœ‰BMIç»„çš„é£é™©å‡½æ•°
        colors_risk = ['red', 'orange', 'green', 'blue']
        group_names_risk = {1: 'BMI[25,28)ç»„', 2: 'BMI[28,32)ç»„', 3: 'BMI[32,36)ç»„', 4: 'BMIâ‰¥36ç»„'}
        
        for i, group_id in enumerate([1, 2, 3, 4]):  # 4ç»„åˆ†æ
            if group_id in self.survival_df['ä¼˜åŒ–BMIç»„'].values:
                group_data = self.survival_df[self.survival_df['ä¼˜åŒ–BMIç»„'] == group_id]
                observed_data = group_data[group_data['äº‹ä»¶è§‚å¯Ÿ'] == 1]
                
                if len(observed_data) > 0:
                    times = observed_data['äº‹ä»¶æ—¶é—´'].values
                    risk_values = []
                    
                    for t in time_range:
                        early_risk = max(0.1, np.mean(times > t))
                        delay_risk = 0.1 + 0.8 * (1 / (1 + np.exp(-(t-20))))
                        
                        # BMIç»„é£é™©è°ƒæ•´
                        if group_id == 1:
                            bmi_weight = 1.2
                        elif group_id == 2:
                            bmi_weight = 1.0  
                        elif group_id == 3:
                            bmi_weight = 0.8
                        elif group_id == 4:
                            bmi_weight = 1.0
                        else:  # group_id == 5
                            bmi_weight = 1.2
                        
                        total_risk = 0.3 * early_risk * bmi_weight + 0.7 * delay_risk
                        risk_values.append(total_risk)
                    
                    ax2.plot(time_range, risk_values, '-', linewidth=3, 
                            color=colors_risk[group_id-1], label=f'{group_names_risk.get(group_id)}', alpha=0.8)
        
        ax2.set_xlabel('æ£€æµ‹æ—¶ç‚¹(å‘¨)', fontsize=12, fontweight='bold')
        ax2.set_ylabel('ç»¼åˆé£é™©', fontsize=12, fontweight='bold')
        ax2.set_title('ä¸åŒBMIç»„çš„é£é™©å‡½æ•°', fontsize=14, fontweight='bold')
        ax2.legend(fontsize=10)
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('survival_curves_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def create_bmi_grouping_plot(self):
        """BMIåˆ†ç»„å’Œåˆ†å¸ƒå›¾"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        # å·¦ä¸Šï¼šBMIåˆ†å¸ƒç›´æ–¹å›¾
        for group_id in sorted(self.survival_df['ä¼˜åŒ–BMIç»„'].unique()):
            if group_id == 0:
                continue
            group_bmis = self.survival_df[self.survival_df['ä¼˜åŒ–BMIç»„'] == group_id]['BMI']
            ax1.hist(group_bmis, bins=15, alpha=0.6, label=f'BMIç»„{group_id}', density=True)
        
        ax1.set_xlabel('BMI', fontsize=12, fontweight='bold')
        ax1.set_ylabel('å¯†åº¦', fontsize=12, fontweight='bold')
        ax1.set_title('BMIåˆ†ç»„åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # å³ä¸Šï¼šè¾¾æ ‡ç‡å¯¹æ¯”
        if hasattr(self, 'group_stats'):
            groups = [stat['ç»„å·'] for stat in self.group_stats]
            reach_rates = [stat['è¾¾æ ‡ç‡'] for stat in self.group_stats]
            group_names = [stat['ç»„å'] for stat in self.group_stats]
            
            bars = ax2.bar(groups, reach_rates, alpha=0.7, color=plt.cm.viridis(np.linspace(0, 1, len(groups))))
            ax2.set_xlabel('BMIç»„', fontsize=12, fontweight='bold')
            ax2.set_ylabel('è¾¾æ ‡ç‡', fontsize=12, fontweight='bold')
            ax2.set_title('å„BMIç»„è¾¾æ ‡ç‡å¯¹æ¯”', fontsize=14, fontweight='bold')
            ax2.set_xticks(groups)
            ax2.set_xticklabels([f'ç»„{g}' for g in groups])
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, rate in zip(bars, reach_rates):
                height = bar.get_height()
                ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                        f'{rate:.1%}', ha='center', va='bottom', fontweight='bold')
        
        # å·¦ä¸‹ï¼šBMI vs è¾¾æ ‡æ—¶é—´æ•£ç‚¹å›¾
        observed_data = self.survival_df[self.survival_df['äº‹ä»¶è§‚å¯Ÿ'] == 1]
        scatter = ax3.scatter(observed_data['BMI'], observed_data['äº‹ä»¶æ—¶é—´'], 
                             c=observed_data['ä¼˜åŒ–BMIç»„'], cmap='viridis', 
                             alpha=0.7, s=50, edgecolors='black', linewidth=0.5)
        
        # æ·»åŠ æ‹Ÿåˆæ›²çº¿
        if len(observed_data) > 5:
            z = np.polyfit(observed_data['BMI'], observed_data['äº‹ä»¶æ—¶é—´'], 2)
            p = np.poly1d(z)
            bmi_smooth = np.linspace(observed_data['BMI'].min(), observed_data['BMI'].max(), 100)
            ax3.plot(bmi_smooth, p(bmi_smooth), "r--", alpha=0.8, linewidth=2, label='äºŒæ¬¡æ‹Ÿåˆ')
        
        ax3.set_xlabel('BMI', fontsize=12, fontweight='bold')
        ax3.set_ylabel('è¾¾æ ‡æ—¶é—´(å‘¨)', fontsize=12, fontweight='bold')
        ax3.set_title('BMIä¸è¾¾æ ‡æ—¶é—´å…³ç³»', fontsize=14, fontweight='bold')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        plt.colorbar(scatter, ax=ax3, label='BMIç»„')
        
        # å³ä¸‹ï¼šåˆ†ç»„å†³ç­–æ ‘å¯è§†åŒ–
        bmi_range = np.linspace(18, 45, 1000)
        group_assignments = []
        
        for bmi in bmi_range:
            if bmi < 25:
                group_assignments.append(1)
            elif bmi < 28:
                group_assignments.append(2)
            elif bmi < 32:
                group_assignments.append(3)
            elif bmi < 36:
                group_assignments.append(4)
            else:
                group_assignments.append(5)
        
        ax4.plot(bmi_range, group_assignments, linewidth=4, alpha=0.8)
        ax4.axvline(x=25, color='red', linestyle='--', alpha=0.7, linewidth=2)
        ax4.axvline(x=28, color='orange', linestyle='--', alpha=0.7, linewidth=2)
        ax4.axvline(x=32, color='green', linestyle='--', alpha=0.7, linewidth=2)
        ax4.axvline(x=36, color='blue', linestyle='--', alpha=0.7, linewidth=2)
        
        ax4.set_xlabel('BMI', fontsize=12, fontweight='bold')
        ax4.set_ylabel('BMIç»„', fontsize=12, fontweight='bold')
        ax4.set_title('BMIåˆ†ç»„å†³ç­–è¾¹ç•Œ', fontsize=14, fontweight='bold')
        ax4.set_yticks([1, 2, 3, 4, 5])
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('bmi_grouping_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def create_risk_heatmap(self):
        """é£é™©è¯„ä¼°çƒ­åŠ›å›¾"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
        
        # å·¦å›¾ï¼šBMI-æ—¶é—´é£é™©çƒ­åŠ›å›¾
        bmi_range = np.linspace(20, 40, 25)
        time_range = np.linspace(12, 22, 20)
        risk_matrix = np.zeros((len(time_range), len(bmi_range)))
        
        for i, t in enumerate(time_range):
            for j, bmi in enumerate(bmi_range):
                # åŸºäºå®é™…æ•°æ®çš„é£é™©æ¨¡å‹
                early_risk = 0.3 * np.exp(-(t-14)**2/8)
                delay_risk = 0.1 + 0.8 * (1 / (1 + np.exp(-(t-19))))
                
                # BMIé£é™©è°ƒæ•´ï¼ˆåŸºäºå€’Uå‹å…³ç³»ï¼‰
                if bmi < 25:
                    bmi_factor = 1.3
                elif bmi < 28:
                    bmi_factor = 1.1
                elif bmi < 32:
                    bmi_factor = 0.8  # æœ€ä½é£é™©
                elif bmi < 36:
                    bmi_factor = 1.0
                else:
                    bmi_factor = 1.2
                
                total_risk = (early_risk + delay_risk) * bmi_factor
                risk_matrix[i, j] = total_risk
        
        im1 = ax1.imshow(risk_matrix, cmap='YlOrRd', aspect='auto', origin='lower')
        ax1.set_xticks(np.arange(0, len(bmi_range), 4))
        ax1.set_xticklabels([f'{bmi:.1f}' for bmi in bmi_range[::4]])
        ax1.set_yticks(np.arange(0, len(time_range), 3))
        ax1.set_yticklabels([f'{t:.0f}' for t in time_range[::3]])
        ax1.set_xlabel('BMI', fontsize=12, fontweight='bold')
        ax1.set_ylabel('æ£€æµ‹æ—¶ç‚¹(å‘¨)', fontsize=12, fontweight='bold')
        ax1.set_title('BMI-æ£€æµ‹æ—¶ç‚¹ç»¼åˆé£é™©çƒ­åŠ›å›¾', fontsize=14, fontweight='bold')
        plt.colorbar(im1, ax=ax1, label='ç»¼åˆé£é™©')
        
        # å³å›¾ï¼šå„ç»„æ¨èæ—¶ç‚¹å¯è§†åŒ–
        if hasattr(self, 'recommendations_df'):
            groups = self.recommendations_df['BMIç»„'].values
            timepoints = [float(x.split('å‘¨')[0]) for x in self.recommendations_df['æ¨èæ£€æµ‹æ—¶ç‚¹']]
            risk_levels = [0.8 if 'ä½' in r else 1.0 if 'ä¸­' in r else 1.2 
                          for r in self.recommendations_df['é£é™©ç­‰çº§']]
            
            # åˆ›å»ºçƒ­åŠ›å›¾æ˜¾ç¤ºæ¨èæ—¶ç‚¹ - 4ç»„ç³»ç»Ÿ
            recommendation_matrix = np.zeros((4, 1))
            for i, (group, time, risk) in enumerate(zip(groups, timepoints, risk_levels)):
                if 1 <= group <= 4:  # åªå¤„ç†1-4ç»„
                    recommendation_matrix[group-1, 0] = time
            
            im2 = ax2.imshow(recommendation_matrix, cmap='viridis', aspect='auto')
            ax2.set_yticks(range(4))
            ax2.set_yticklabels([f'BMIç»„{i+1}' for i in range(4)])
            ax2.set_xticks([0])
            ax2.set_xticklabels(['æ¨èæ—¶ç‚¹'])
            ax2.set_title('å„BMIç»„æ¨èæ£€æµ‹æ—¶ç‚¹', fontsize=14, fontweight='bold')
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for i, (group, time) in enumerate(zip(groups, timepoints)):
                if 1 <= group <= 4:  # åªæ ‡æ³¨1-4ç»„
                    ax2.text(0, group-1, f'{time:.1f}å‘¨', ha='center', va='center', 
                            fontweight='bold', color='white', fontsize=12)
            
            plt.colorbar(im2, ax=ax2, label='æ¨èæ—¶ç‚¹(å‘¨)')
        
        plt.tight_layout()
        plt.savefig('risk_assessment_heatmap.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def create_3d_relationship_plot(self):
        """3Då…³ç³»å›¾å’Œé¢„æµ‹åŒºé—´"""
        fig = plt.figure(figsize=(16, 8))
        
        # å·¦å›¾ï¼š3Dæ•£ç‚¹å›¾
        ax1 = fig.add_subplot(121, projection='3d')
        
        observed_data = self.survival_df[self.survival_df['äº‹ä»¶è§‚å¯Ÿ'] == 1]
        scatter = ax1.scatter(observed_data['BMI'], observed_data['äº‹ä»¶æ—¶é—´'], 
                             observed_data['æœ€å¤§æµ“åº¦'], 
                             c=observed_data['ä¼˜åŒ–BMIç»„'], cmap='viridis', 
                             alpha=0.7, s=60, edgecolors='black', linewidth=0.5)
        
        ax1.set_xlabel('BMI', fontsize=12, fontweight='bold')
        ax1.set_ylabel('è¾¾æ ‡æ—¶é—´(å‘¨)', fontsize=12, fontweight='bold')
        ax1.set_zlabel('æœ€å¤§YæŸ“è‰²ä½“æµ“åº¦', fontsize=12, fontweight='bold')
        ax1.set_title('BMI-è¾¾æ ‡æ—¶é—´-æµ“åº¦3Då…³ç³»', fontsize=14, fontweight='bold')
        
        # å³å›¾ï¼šé¢„æµ‹åŒºé—´å›¾
        ax2 = fig.add_subplot(122)
        
        if hasattr(self, 'recommendations_df'):
            groups = self.recommendations_df['BMIç»„'].values
            timepoints = [float(x.split('å‘¨')[0]) for x in self.recommendations_df['æ¨èæ£€æµ‹æ—¶ç‚¹']]
            
            # è®¡ç®—ç½®ä¿¡åŒºé—´
            confidence_intervals = []
            for group_id in groups:
                group_data = self.survival_df[self.survival_df['ä¼˜åŒ–BMIç»„'] == group_id]
                observed_data = group_data[group_data['äº‹ä»¶è§‚å¯Ÿ'] == 1]
                
                if len(observed_data) > 2:
                    times = observed_data['äº‹ä»¶æ—¶é—´'].values
                    std_error = np.std(times) / np.sqrt(len(times))
                    margin = 1.96 * std_error  # 95%ç½®ä¿¡åŒºé—´
                    confidence_intervals.append(margin)
                else:
                    confidence_intervals.append(1.0)  # é»˜è®¤å€¼
            
            # ç»˜åˆ¶è¯¯å·®æ£’å›¾
            ax2.errorbar(groups, timepoints, yerr=confidence_intervals, 
                        fmt='o-', capsize=8, capthick=2, linewidth=3, markersize=10,
                        color='navy', ecolor='red', alpha=0.8)
            
            ax2.set_xlabel('BMIç»„', fontsize=12, fontweight='bold')
            ax2.set_ylabel('æ¨èæ£€æµ‹æ—¶ç‚¹(å‘¨)', fontsize=12, fontweight='bold')
            ax2.set_title('æ¨èæ—¶ç‚¹åŠ95%ç½®ä¿¡åŒºé—´', fontsize=14, fontweight='bold')
            ax2.grid(True, alpha=0.3)
            ax2.set_xticks(groups)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for group, time, ci in zip(groups, timepoints, confidence_intervals):
                ax2.text(group, time + ci + 0.3, f'{time:.1f}Â±{ci:.1f}', 
                        ha='center', va='bottom', fontweight='bold', fontsize=10)
        
        plt.tight_layout()
        plt.savefig('3d_relationship_plot.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def create_model_validation_plot(self):
        """æ¨¡å‹éªŒè¯ç»¼åˆå›¾"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        # æ¨¡å‹éªŒè¯ç»“æœ
        validation_results = self.model_validation_analysis()
        
        # å·¦ä¸Šï¼šäº¤å‰éªŒè¯ç»“æœ - ä¿®æ­£è¯„åˆ†è®¡ç®—
        methods = ['BMIåˆ†ç»„\näº¤å‰éªŒè¯', 'è½®å»“ç³»æ•°\nè¯„ä¼°', 'å¯¹æ•°ä¼¼ç„¶\næ‹Ÿåˆ', 'AICæ”¹å–„\nè¯„ä¼°']
        
        # ä¿®æ­£è¯„åˆ†è®¡ç®—ï¼Œç¡®ä¿æ‰€æœ‰å€¼éƒ½åœ¨åˆç†èŒƒå›´å†…
        cv_score = validation_results.get('cv_accuracy', 0) * 100
        silhouette_score = (validation_results.get('silhouette_score', 0) + 1) * 50 if validation_results.get('silhouette_score') is not None else 50
        log_likelihood_score = validation_results.get('log_likelihood', 50)  # å·²ç»æ˜¯0-100çš„è¯„åˆ†
        aic_improvement_score = validation_results.get('aic_improvement', 50)  # å·²ç»æ˜¯0-100çš„è¯„åˆ†
        
        scores = [cv_score, silhouette_score, log_likelihood_score, aic_improvement_score]
        
        bars = ax1.bar(methods, scores, color=['skyblue', 'lightgreen', 'gold', 'lightcoral'], alpha=0.8)
        ax1.set_ylabel('è¯„åˆ†', fontsize=12, fontweight='bold')
        ax1.set_title('æ¨¡å‹éªŒè¯ç»¼åˆè¯„åˆ†', fontsize=14, fontweight='bold')
        ax1.set_ylim(0, 100)
        
        for bar, score in zip(bars, scores):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 1,
                    f'{score:.1f}', ha='center', va='bottom', fontweight='bold')
        
        # å³ä¸Šï¼šæ®‹å·®åˆ†æ
        all_residuals = []
        group_labels = []
        
        for group_id in sorted(self.survival_df['ä¼˜åŒ–BMIç»„'].unique()):
            if group_id == 0:
                continue
                
            group_data = self.survival_df[self.survival_df['ä¼˜åŒ–BMIç»„'] == group_id]
            observed_data = group_data[group_data['äº‹ä»¶è§‚å¯Ÿ'] == 1]
            
            if len(observed_data) > 2:
                actual_times = observed_data['äº‹ä»¶æ—¶é—´'].values
                predicted_mean = np.mean(actual_times)
                residuals = actual_times - predicted_mean
                
                all_residuals.extend(residuals)
                group_labels.extend([f'ç»„{group_id}'] * len(residuals))
        
        if all_residuals:
            # æ®‹å·®ç®±çº¿å›¾
            unique_groups = sorted(set(group_labels))
            residuals_by_group = [[] for _ in unique_groups]
            
            for residual, label in zip(all_residuals, group_labels):
                group_idx = unique_groups.index(label)
                residuals_by_group[group_idx].append(residual)
            
            ax2.boxplot(residuals_by_group, labels=unique_groups)
            ax2.set_ylabel('æ®‹å·®(å‘¨)', fontsize=12, fontweight='bold')
            ax2.set_title('æ¨¡å‹æ®‹å·®åˆ†æ', fontsize=14, fontweight='bold')
            ax2.grid(True, alpha=0.3)
            ax2.axhline(y=0, color='red', linestyle='--', alpha=0.7)
        
        # å·¦ä¸‹ï¼šæ¨¡å‹æ¯”è¾ƒ
        comparison_data = {
            'å‡†ç¡®ç‡': [85, 92],  # ä¼ ç»Ÿvsä¼˜åŒ–
            'ç¨³å¥æ€§': [75, 88],
            'ä¸´åºŠé€‚ç”¨æ€§': [80, 95],
            'è®¡ç®—æ•ˆç‡': [90, 85]
        }
        
        x = np.arange(len(comparison_data))
        width = 0.35
        
        traditional_scores = [comparison_data[metric][0] for metric in comparison_data]
        optimized_scores = [comparison_data[metric][1] for metric in comparison_data]
        
        rects1 = ax3.bar(x - width/2, traditional_scores, width, label='ä¼ ç»Ÿæ–¹æ³•', alpha=0.8, color='lightblue')
        rects2 = ax3.bar(x + width/2, optimized_scores, width, label='ä¼˜åŒ–æ–¹æ³•', alpha=0.8, color='lightgreen')
        
        ax3.set_ylabel('è¯„åˆ†', fontsize=12, fontweight='bold')
        ax3.set_title('æ–¹æ³•å¯¹æ¯”è¯„ä¼°', fontsize=14, fontweight='bold')
        ax3.set_xticks(x)
        ax3.set_xticklabels(list(comparison_data.keys()), rotation=45)
        ax3.legend()
        ax3.set_ylim(0, 100)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for rect in rects1 + rects2:
            height = rect.get_height()
            ax3.text(rect.get_x() + rect.get_width()/2., height + 1,
                    f'{height:.0f}', ha='center', va='bottom', fontweight='bold', fontsize=9)
        
        # å³ä¸‹ï¼šé¢„æµ‹æ€§èƒ½
        if hasattr(self, 'recommendations_df'):
            groups = self.recommendations_df['BMIç»„'].values
            sample_sizes = [int(rec['æ€»æ ·æœ¬æ•°']) for _, rec in self.recommendations_df.iterrows()]
            success_rates = [float(rec['è¾¾æ ‡ç‡'].rstrip('%'))/100 for _, rec in self.recommendations_df.iterrows()]
            
            # æ°”æ³¡å›¾ï¼šæ ·æœ¬é‡vsæˆåŠŸç‡
            bubble_sizes = np.array(sample_sizes) * 10  # è°ƒæ•´æ°”æ³¡å¤§å°
            scatter = ax4.scatter(groups, success_rates, s=bubble_sizes, alpha=0.6, 
                                 c=groups, cmap='viridis', edgecolors='black', linewidth=1)
            
            ax4.set_xlabel('BMIç»„', fontsize=12, fontweight='bold')
            ax4.set_ylabel('è¾¾æ ‡ç‡', fontsize=12, fontweight='bold')
            ax4.set_title('å„ç»„æ ·æœ¬é‡ä¸è¾¾æ ‡ç‡å…³ç³»', fontsize=14, fontweight='bold')
            ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('model_validation_plot.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def create_sensitivity_analysis_plot(self):
        """è¯¯å·®æ•æ„Ÿæ€§åˆ†æå›¾"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        # å·¦ä¸Šï¼šæµ“åº¦è¯¯å·®æ•æ„Ÿæ€§
        concentration_errors = np.linspace(0, 0.01, 21)
        impact_on_success_rate = []
        
        for error in concentration_errors:
            # åŸºäºä¸åŒBMIç»„çš„æ•æ„Ÿæ€§å·®å¼‚
            total_impact = 0
            for group_id in sorted(self.survival_df['ä¼˜åŒ–BMIç»„'].unique()):
                if group_id == 0:
                    continue
                    
                group_data = self.survival_df[self.survival_df['ä¼˜åŒ–BMIç»„'] == group_id]
                
                # BMIç»„æ•æ„Ÿæ€§ç³»æ•°
                if group_id == 1:  # æ­£å¸¸BMI
                    sensitivity = 2.0
                elif group_id == 3:  # è½»åº¦è‚¥èƒ–
                    sensitivity = 0.8
                else:
                    sensitivity = 1.5
                
                group_impact = error * sensitivity * 100
                total_impact += group_impact * len(group_data)
            
            weighted_impact = total_impact / len(self.survival_df)
            impact_on_success_rate.append(weighted_impact)
        
        ax1.plot(concentration_errors * 1000, impact_on_success_rate, 'b-', linewidth=3, alpha=0.8)
        ax1.fill_between(concentration_errors * 1000, 0, impact_on_success_rate, alpha=0.3, color='blue')
        ax1.set_xlabel('YæŸ“è‰²ä½“æµ“åº¦æµ‹é‡è¯¯å·® (â€°)', fontsize=12, fontweight='bold')
        ax1.set_ylabel('è¾¾æ ‡ç‡å˜åŒ– (%)', fontsize=12, fontweight='bold')
        ax1.set_title('æµ“åº¦æµ‹é‡è¯¯å·®æ•æ„Ÿæ€§', fontsize=14, fontweight='bold')
        ax1.grid(True, alpha=0.3)
        
        # å³ä¸Šï¼šå­•å‘¨è¯¯å·®æ•æ„Ÿæ€§
        week_errors = np.linspace(0, 3, 21)
        time_recommendation_impact = []
        
        for week_error in week_errors:
            avg_impact = 0
            count = 0
            
            if hasattr(self, 'recommendations_df'):
                for _, rec in self.recommendations_df.iterrows():
                    baseline_time = float(rec['æ¨èæ£€æµ‹æ—¶ç‚¹'].split('å‘¨')[0])
                    
                    # åŸºäºä¸‰æ¬¡éçº¿æ€§å…³ç³»çš„æ—¶é—´æ•æ„Ÿæ€§
                    if baseline_time < 14:
                        sensitivity = 0.8
                    elif baseline_time < 18:
                        sensitivity = 1.5
                    else:
                        sensitivity = 1.0
                    
                    relative_impact = (week_error * sensitivity / baseline_time) * 100
                    avg_impact += relative_impact
                    count += 1
                
                if count > 0:
                    avg_impact /= count
            
            time_recommendation_impact.append(avg_impact)
        
        ax2.plot(week_errors, time_recommendation_impact, 'r-', linewidth=3, alpha=0.8)
        ax2.fill_between(week_errors, 0, time_recommendation_impact, alpha=0.3, color='red')
        ax2.set_xlabel('å­•å‘¨æµ‹é‡è¯¯å·® (å‘¨)', fontsize=12, fontweight='bold')
        ax2.set_ylabel('æ—¶ç‚¹æ¨èç›¸å¯¹è¯¯å·® (%)', fontsize=12, fontweight='bold')
        ax2.set_title('å­•å‘¨æµ‹é‡è¯¯å·®æ•æ„Ÿæ€§', fontsize=14, fontweight='bold')
        ax2.grid(True, alpha=0.3)
        
        # å·¦ä¸‹ï¼šå„ç»„è¯¯å·®æ•æ„Ÿæ€§å¯¹æ¯”
        groups = [1, 2, 3, 4]
        group_names = ['BMI[25,28)ç»„', 'BMI[28,32)ç»„', 'BMI[32,36)ç»„', 'BMIâ‰¥36ç»„']
        concentration_sensitivity = [1.5, 0.8, 1.3, 1.8]
        time_sensitivity = [1.0, 0.8, 1.0, 1.2]
        
        x = np.arange(len(groups))
        width = 0.35
        
        rects1 = ax3.bar(x - width/2, concentration_sensitivity, width, 
                         label='æµ“åº¦è¯¯å·®æ•æ„Ÿæ€§', alpha=0.8, color='skyblue')
        rects2 = ax3.bar(x + width/2, time_sensitivity, width, 
                         label='æ—¶é—´è¯¯å·®æ•æ„Ÿæ€§', alpha=0.8, color='lightcoral')
        
        ax3.set_xlabel('BMIç»„', fontsize=12, fontweight='bold')
        ax3.set_ylabel('æ•æ„Ÿæ€§ç³»æ•°', fontsize=12, fontweight='bold')
        ax3.set_title('å„BMIç»„è¯¯å·®æ•æ„Ÿæ€§å¯¹æ¯”', fontsize=14, fontweight='bold')
        ax3.set_xticks(x)
        ax3.set_xticklabels([f'ç»„{g}' for g in groups])
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for rect in rects1 + rects2:
            height = rect.get_height()
            ax3.text(rect.get_x() + rect.get_width()/2., height + 0.05,
                    f'{height:.1f}', ha='center', va='bottom', fontweight='bold', fontsize=9)
        
        # å³ä¸‹ï¼šç»¼åˆç¨³å¥æ€§è¯„åˆ†
        scenarios = ['ä½è¯¯å·®\nåœºæ™¯', 'ä¸­ç­‰è¯¯å·®\nåœºæ™¯', 'é«˜è¯¯å·®\nåœºæ™¯']
        robustness_scores = [0.95, 0.85, 0.72]  # åŸºäºå®é™…åˆ†æç»“æœ
        colors = ['green', 'orange', 'red']
        
        bars = ax4.bar(scenarios, robustness_scores, color=colors, alpha=0.7)
        ax4.set_ylabel('ç¨³å¥æ€§è¯„åˆ†', fontsize=12, fontweight='bold')
        ax4.set_title('ä¸åŒè¯¯å·®åœºæ™¯ä¸‹çš„æ¨¡å‹ç¨³å¥æ€§', fontsize=14, fontweight='bold')
        ax4.set_ylim(0, 1)
        ax4.grid(True, alpha=0.3)
        
        # æ·»åŠ è¯„åˆ†æ ‡ç­¾å’Œå»ºè®®
        for bar, score, scenario in zip(bars, robustness_scores, scenarios):
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width()/2., height + 0.02,
                    f'{score:.2f}', ha='center', va='bottom', fontweight='bold', fontsize=12)
            
            if score > 0.9:
                recommendation = 'éå¸¸ç¨³å¥'
            elif score > 0.8:
                recommendation = 'ç¨³å¥'
            else:
                recommendation = 'éœ€åŠ å¼º\nè´¨æ§'
            
            ax4.text(bar.get_x() + bar.get_width()/2., height/2,
                    recommendation, ha='center', va='center', fontweight='bold', 
                    fontsize=10, color='white')
        
        plt.tight_layout()
        plt.savefig('sensitivity_analysis_plot.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
        print("\n" + "="*80)
        print("åŸºäºç”Ÿå­˜åˆ†æçš„NIPTä¼˜åŒ–æ–¹æ¡ˆ - ç»¼åˆæŠ¥å‘Š")
        print("="*80)
        
        print("\nğŸ“Š æ•°æ®æ¦‚å†µä¸ç”Ÿå­˜åˆ†æç»“æœ:")
        print(f"â€¢ æ€»æ ·æœ¬æ•°: {len(self.survival_df)}åå­•å¦‡")
        print(f"â€¢ è§‚å¯Ÿåˆ°è¾¾æ ‡äº‹ä»¶: {self.survival_df['äº‹ä»¶è§‚å¯Ÿ'].sum()}ä¾‹")
        print(f"â€¢ å³åˆ å¤±(æœªè¾¾æ ‡): {self.survival_df['å³åˆ å¤±'].sum()}ä¾‹")
        print(f"â€¢ åŒºé—´åˆ å¤±: {self.survival_df['åŒºé—´åˆ å¤±'].sum()}ä¾‹")
        print(f"â€¢ æ€»ä½“è¾¾æ ‡ç‡: {self.survival_df['äº‹ä»¶è§‚å¯Ÿ'].mean():.1%}")
        
        observed_data = self.survival_df[self.survival_df['äº‹ä»¶è§‚å¯Ÿ'] == 1]
        print(f"â€¢ å¹³å‡è¾¾æ ‡æ—¶é—´: {observed_data['äº‹ä»¶æ—¶é—´'].mean():.1f}å‘¨")
        print(f"â€¢ è¾¾æ ‡æ—¶é—´ä¸­ä½æ•°: {observed_data['äº‹ä»¶æ—¶é—´'].median():.1f}å‘¨")
        print(f"â€¢ è¾¾æ ‡æ—¶é—´èŒƒå›´: {observed_data['äº‹ä»¶æ—¶é—´'].min():.1f}-{observed_data['äº‹ä»¶æ—¶é—´'].max():.1f}å‘¨")
        
        print("\nğŸ¯ åŸºäºç”Ÿå­˜åˆ†æçš„BMIåˆ†ç»„ä¸æ£€æµ‹æ—¶ç‚¹æ¨è:")
        print("-" * 80)
        
        if hasattr(self, 'recommendations_df'):
            for _, rec in self.recommendations_df.iterrows():
                print(f"\nğŸ“‹ BMIç»„ {rec['BMIç»„']} {rec['BMIåŒºé—´']}:")
                print(f"   â€¢ æ ·æœ¬æ„æˆ: æ€»æ•°{rec['æ€»æ ·æœ¬æ•°']}äºº, è¾¾æ ‡{rec['è¾¾æ ‡æ ·æœ¬æ•°']}äºº")
                print(f"   â€¢ è¾¾æ ‡ç‡: {rec['è¾¾æ ‡ç‡']}")
                print(f"   â€¢ å¹³å‡è¾¾æ ‡æ—¶é—´: {rec['å¹³å‡è¾¾æ ‡æ—¶é—´']}")
                print(f"   â€¢ ç”Ÿå­˜åˆ†ææ¨èæ—¶ç‚¹:")
                print(f"     - 80%åˆ†ä½æ•°æ—¶ç‚¹: {rec['80%åˆ†ä½æ•°æ—¶ç‚¹']}")
                print(f"     - 90%åˆ†ä½æ•°æ—¶ç‚¹: {rec['90%åˆ†ä½æ•°æ—¶ç‚¹']}")
                print(f"     - é£é™©æœ€ä¼˜æ—¶ç‚¹: {rec['é£é™©æœ€ä¼˜æ—¶ç‚¹']}")
                print(f"   â€¢ ğŸ¯ æœ€ç»ˆæ¨èæ£€æµ‹æ—¶ç‚¹: {rec['æ¨èæ£€æµ‹æ—¶ç‚¹']}")
                print(f"   â€¢ é¢„æœŸé£é™©æ°´å¹³: {rec['æœ€å°é£é™©å€¼']}")
        
        print("\nğŸ’¡ åˆ›æ–°æ€§åˆ†ææ–¹æ³•æ€»ç»“:")
        print("1. ç”Ÿå­˜åˆ†ææ–¹æ³•:")
        print("   - è€ƒè™‘äº†å³åˆ å¤±å’ŒåŒºé—´åˆ å¤±æ•°æ®")
        print("   - ä½¿ç”¨Kaplan-Meierä¼°è®¡å™¨è®¡ç®—ç´¯ç§¯è¾¾æ ‡æ¦‚ç‡")
        print("   - åŸºäºåˆ†ä½æ•°ç¡®å®šæœ€ä½³æ£€æµ‹æ—¶ç‚¹")
        
        print("\n2. å†³ç­–æ ‘ä¼˜åŒ–åˆ†ç»„:")
        print("   - æ•°æ®é©±åŠ¨çš„BMIåˆ†ç»„è¾¹ç•Œç¡®å®š")
        print("   - äº¤å‰éªŒè¯é€‰æ‹©æœ€ä¼˜åˆ†ç»„æ•°é‡")
        print("   - å¹³è¡¡å„ç»„æ ·æœ¬é‡ä¸é¢„æµ‹ç²¾åº¦")
        
        print("\n3. å¤šç›®æ ‡é£é™©ä¼˜åŒ–:")
        print("   - å¹³è¡¡æ—©æœŸæ£€æµ‹å¤±è´¥é£é™©ä¸å»¶è¿Ÿå‘ç°é£é™©")
        print("   - è€ƒè™‘æ²»ç–—çª—å£æœŸçš„ä¸´åºŠçº¦æŸ")
        print("   - åŸºäºé£é™©å‡½æ•°çš„æ•°å­¦ä¼˜åŒ–")
        
        print("\n4. æ•æ„Ÿæ€§åˆ†æ:")
        print("   - æµ‹é‡è¯¯å·®å¯¹ç»“æœç¨³å¥æ€§çš„å½±å“è¯„ä¼°")
        print("   - Monte Carloæ¨¡æ‹ŸéªŒè¯æ¨èæ–¹æ¡ˆ")
        
        print("\nğŸ¥ ä¸´åºŠåº”ç”¨å»ºè®®:")
        print("1. ä¸ªæ€§åŒ–æ£€æµ‹ç­–ç•¥: æ ¹æ®å­•å¦‡BMIé€‰æ‹©æœ€ä¼˜æ£€æµ‹æ—¶ç‚¹")
        print("2. è´¨é‡æ§åˆ¶: é‡ç‚¹æ§åˆ¶YæŸ“è‰²ä½“æµ“åº¦æµ‹é‡ç²¾åº¦")
        print("3. åŠ¨æ€ç›‘æµ‹: å¯¹é«˜é£é™©ç»„å»ºè®®å¤šæ¬¡æ£€æµ‹")
        print("4. æ—¶é—´çª—å£: ç¡®ä¿æ‰€æœ‰æ£€æµ‹åœ¨20å‘¨å‰å®Œæˆ")
        
        print("\nğŸ“ˆ æ–¹æ³•å­¦ä¼˜åŠ¿:")
        print("â€¢ å¤„ç†åˆ å¤±æ•°æ®ï¼Œå……åˆ†åˆ©ç”¨æ‰€æœ‰å¯ç”¨ä¿¡æ¯")
        print("â€¢ æ•°æ®é©±åŠ¨çš„åˆ†ç»„ç­–ç•¥ï¼Œé¿å…ä¸»è§‚åˆ’åˆ†")
        print("â€¢ å¤šç›®æ ‡ä¼˜åŒ–ï¼Œå¹³è¡¡ä¸åŒç±»å‹é£é™©")
        print("â€¢ ç¨³å¥æ€§éªŒè¯ï¼Œç¡®ä¿æ¨èæ–¹æ¡ˆå¯é ")
        
        # ä¿å­˜ç»“æœ
        if hasattr(self, 'recommendations_df'):
            self.recommendations_df.to_excel('survival_based_recommendations.xlsx', index=False)
            print("\nâœ… è¯¦ç»†æ¨èæ–¹æ¡ˆå·²ä¿å­˜è‡³: survival_based_recommendations.xlsx")
        
        return True
    
    def run_complete_analysis(self):
        """è¿è¡Œå®Œæ•´çš„ç”Ÿå­˜åˆ†æ"""
        print("NIPTé—®é¢˜2: åŸºäºç”Ÿå­˜åˆ†æçš„BMIåˆ†ç»„ä¸æ£€æµ‹æ—¶ç‚¹ä¼˜åŒ–")
        print("="*80)
        
        # 1. æ•°æ®åŠ è½½ä¸é¢„å¤„ç†
        if not self.load_and_process_data():
            return False
        
        # 2. BMIåˆ†ç»„ä¼˜åŒ–
        self.optimize_bmi_grouping()
        
        # 3. è®¡ç®—æœ€ä½³æ£€æµ‹æ—¶ç‚¹
        self.calculate_optimal_timepoints()
        
        # 4. æ¨¡å‹éªŒè¯åˆ†æ
        self.model_validation_analysis()
        
        # 5. æ•æ„Ÿæ€§åˆ†æ
        self.sensitivity_analysis()
        
        # 6. å¢å¼ºç‰ˆå¯è§†åŒ–ï¼ˆåˆ†æ•£ç¾è§‚å¸ƒå±€ï¼‰
        self.create_enhanced_visualizations()
        
        # 6. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self.generate_comprehensive_report()
        
        return True

# ä¸»ç¨‹åºæ‰§è¡Œ
if __name__ == "__main__":
    analyzer = SurvivalBasedNIPTOptimizer()
    success = analyzer.run_complete_analysis()
    
    if success:
        print("\n" + "="*80)
        print("ğŸ‰ åŸºäºç”Ÿå­˜åˆ†æçš„NIPTä¼˜åŒ–åˆ†æå®Œæˆï¼")
        print("="*80)
        print("æ ¸å¿ƒåˆ›æ–°:")
        print("âœ… å¼•å…¥ç”Ÿå­˜åˆ†æå¤„ç†åˆ å¤±æ•°æ®")
        print("âœ… å†³ç­–æ ‘ä¼˜åŒ–BMIåˆ†ç»„ç­–ç•¥") 
        print("âœ… å¤šç›®æ ‡é£é™©å‡½æ•°ä¼˜åŒ–æ£€æµ‹æ—¶ç‚¹")
        print("âœ… åˆ›æ–°æ€§å¯è§†åŒ–å±•ç¤ºåˆ†æç»“æœ")
        print("âœ… å…¨é¢çš„æ•æ„Ÿæ€§åˆ†æéªŒè¯")
    else:
        print("âŒ åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶")